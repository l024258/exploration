{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install crewai==0.55.2 crewai-tools==0.12.1\n",
    "# %pip install google-ai-generativelanguage==0.6.9\n",
    "\n",
    "# %pip install protobuf==5.26.1\n",
    "# %pip install langchain-core==0.2.43\n",
    "!pip list | grep lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/L024258/lilly_work/github-copilot/exploration/crewAI/..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import pprint\n",
    "\n",
    "# Get the current working directory and add the parent directory to the Python path\n",
    "current_working_directory = os.getcwd()\n",
    "print(os.path.join(current_working_directory, \"..\"))\n",
    "sys.path.append(os.path.join(current_working_directory, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10ae1f130>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10ae50a90>, root_client=<openai.lib.azure.AzureOpenAI object at 0x107dd5180>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x10ae1f160>, temperature=0.0, max_tokens=4096, deployment_name='gpt-4o-mini', openai_api_version='2023-05-15')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.llm import LLM\n",
    "\n",
    "model = LLM('gpt-4o-mini')\n",
    "llm = model.load_model()\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is New Delhi.', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5154047bf2', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-5dfd16f4-8dc2-4e5d-b68c-14788541e469-0', usage_metadata={'input_tokens': 14, 'output_tokens': 8, 'total_tokens': 22})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OTEL_SDK_DISABLED\"] = \"true\"\n",
    "os.environ[\"CREWAI_TELEMETRY_OPT_OUT\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tavily Search\n",
    "\n",
    "1000 search credit / month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "tavily_search = TavilySearchResults(\n",
    "    max_results=5,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=False,\n",
    "    include_raw_content=True,\n",
    "    include_images=True,\n",
    "    # include_domains=[...],\n",
    "    # exclude_domains=[...],\n",
    "    # name=\"...\",            # overwrite default tool name\n",
    "    # description=\"...\",     # overwrite default tool description\n",
    "    # args_schema=...,       # overwrite default args_schema: BaseModel\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tavily_search.invoke({\"query\": \"What happened with the SENSEX yesterday?\"})\n",
    "pprint.pp(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serper Search\n",
    "\n",
    "Total: 2500 search credit free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "serper_search = GoogleSerperAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = serper_search.results(\"Studies on cardiovascular impacts of weight loss drug from Lilly?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crew with single agent and single task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 09:24:42,225 - 8638448192 - __init__.py-__init__:1231 - WARNING: SDK is disabled.\n",
      "2025-01-03 09:24:42,229 - 8638448192 - __init__.py-__init__:1231 - WARNING: SDK is disabled.\n",
      "2025-01-03 09:24:42,232 - 8638448192 - manager.py-manager:293 - WARNING: Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [2025-01-03 09:24:42][DEBUG]: == Working Agent: Researcher\u001b[00m\n",
      "\u001b[1m\u001b[95m [2025-01-03 09:24:42][INFO]: == Starting Task: Find and summarize the latest AI news\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mI need to gather the latest AI news to provide a comprehensive summary. I will use the search tool to find the most recent and relevant information.\n",
      "\n",
      "Action: tavily_search_results_json  \n",
      "Action Input: {\"query\":\"latest AI news\"}  \n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 09:24:51,353 - 8638448192 - __init__.py-__init__:1231 - WARNING: SDK is disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m \n",
      "\n",
      "[{'url': 'https://www.nbcnews.com/artificial-intelligence', 'content': \"Artificial intelligence news: Chat AI, ChatGPT, AI generator, AI Chatbot and Bard | NBC News NBC News Now The latest news and top stories on artificial intelligence, including ChatGPT, AI Chatbot and Bard. AI NEWS Justine Goode / NBC News / Getty Images NBC News NOW NBC News NOW NBC News NOW NBC News NOW NBC News NOW NBC News NOW NBC News NOW NBC News NOW MORE AI NEWS Taylor Swift criticized a viral AI image of her 'endorsing' Trump. The AI image’s creator spoke to NBC News. Google to relaunch controversial tool for creating AI images after inaccuracies ------------------------------------------------------------------------------- Trump shares AI images of Taylor Swift and her fans supporting him ------------------------------------------------------------------ X’s AI image generator debuts with few guardrails on political content ----------------------------------------------------------------------\"}, {'url': 'https://news.mit.edu/topic/artificial-intelligence2', 'content': 'October 30, 2023\\nRead full story →\\nAccelerating AI tasks while preserving data security\\nThe SecureLoop search tool efficiently identifies secure designs for hardware that can boost the performance of complex AI tasks, while requiring less energy.\\nOctober 30, 2023\\nRead full story →\\nThe brain may learn about the world the same way some computational models do\\nTwo studies find “self-supervised” models, which learn about their environment from unlabeled data, can show activity patterns similar to those of the mammalian brain.\\nOctober 30, 2023\\nRead full story →\\nCelebrating Kendall Square’s past and shaping its future\\nThe 15th Kendall Square Association annual meeting explored new and old aspects of the neighborhood.\\nOctober 23, 2023\\nRead full story →\\nTo excel at engineering design, generative AI must learn to innovate, study finds\\nAI models that prioritize similarity falter when asked to design something completely new.\\n Suggestions or feedback?\\nMIT News | Massachusetts Institute of Technology\\nBrowse By\\nTopics\\nDepartments\\nCenters, Labs, & Programs\\nSchools\\nTopic\\nArtificial intelligence\\nDownload RSS feed: News Articles / In the Media / Audio\\nSearch algorithm reveals nearly 200 new kinds of CRISPR systems\\nBy analyzing bacterial data, researchers have discovered thousands of rare new CRISPR systems that have a range of functions and could enable gene editing, diagnostics, and more.\\n November 15, 2023\\nRead full story →\\nExplained: Generative AI\\nHow do powerful generative AI systems like ChatGPT work, and what makes them different from other types of artificial intelligence?\\nNovember 9, 2023\\nRead full story →\\nUsing AI to optimize for rapid neural imaging\\nMIT CSAIL researchers combine AI and electron microscopy to expedite detailed brain network mapping, aiming to enhance connectomics research and clinical pathology.\\n November 2, 2023\\nRead full story →\\nNew techniques efficiently accelerate sparse tensors for massive AI models\\nComplimentary approaches — “HighLight” and “Tailors and Swiftiles” — could boost the performance of demanding machine-learning tasks.\\n November 21, 2023\\nRead full story →\\nSynthetic imagery sets new bar in AI training efficiency\\nMIT CSAIL researchers innovate with synthetic imagery to train AI, paving the way for more efficient and bias-reduced machine learning.\\n'}, {'url': 'https://www.futuretools.io/news', 'content': \"Yahoo Mail Updates App with AI Tools and New Design ( betanews.com )  InVideo launches AI-powered video creation feature using prompts ( techcrunch.com )  OpenAI to Launch 'Operator' AI Agent Tool in January for Task Automation ( bloomberg.com )  Perplexity to Introduce Ads on Its AI-Powered Search Platform ( techcrunch.com )  YouTube tests AI-generated music remixes in 30-second snippets ( theverge.com )  Particle Introduces AI News App to Support Publishers, Not Replace Them ( techcrunch.com )  X tests free access to AI chatbot Grok in New Zealand ( techcrunch.com )  Microsoft Outlook introduces AI-generated personalized themes ( techcrunch.com )  Trump's Victory: Implications for AI Regulation in the US ( techcrunch.com )  NVIDIA Unveils New AI and Simulation Tools to Accelerate Robot Development ( blogs.nvidia.com ) \"}, {'url': 'https://techcrunch.com/category/artificial-intelligence/', 'content': 'AI News & Artificial Intelligence | TechCrunch AI News & Artificial Intelligence | TechCrunch AI Site Search Toggle AI AI News coverage on artificial intelligence and machine learning tech, the companies building them, and the ethical issues AI raises today. AI AI AI AI AI AI AI Juna.ai wants to use AI agents to make factories more energy-efficient Norwegian startup Factiverse wants to fight disinformation with AI AI A popular technique to make AI more efficient has drawbacks AI AI AI AI Here’s the full list of 44 US AI startups that have raised $100M or more in 2024 OpenAI at one point considered acquiring AI chip startup Cerebras AI AI AI AI AI A popular technique to make AI more efficient has drawbacks'}, {'url': 'https://ai.google/latest-news/', 'content': 'Latest AI news and blog posts – Google AI - Google AI Making AI helpful for everyone Why AI For over 20 years, Google has worked to make AI helpful for everyone. AI research Why AI Milestones AI research Social impact We’re building and deploying AI responsibly Working together to build AI that’s helpful for everyone. AI Principles Responsibility and safety Policy Building for everyone Explore the everyday helpfulness of AI. Help shape the future of AI at Google Labs. Gemini ecosystem Products Experiments For developers Explore our models For organizations Read about the latest in AI 8 ways we’re using AI to help cities be more sustainable Read article People & AI Research Blog Visit blog Responsible AI for Developers Blog Visit blog'}]\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: I have gathered the latest AI news from various sources. Now, I will summarize the top 5 most important pieces of news.\n",
      "\n",
      "Final Answer:\n",
      "- **Google to Relaunch AI Image Tool**: Google is set to relaunch a controversial tool for creating AI images after addressing previous inaccuracies that raised concerns about misinformation.\n",
      "- **AI and Data Security**: Researchers have developed a new search tool called SecureLoop that enhances the performance of complex AI tasks while ensuring data security and reducing energy consumption.\n",
      "- **OpenAI's New Tool**: OpenAI plans to launch an AI agent tool named 'Operator' in January, aimed at automating various tasks for users.\n",
      "- **AI in Video Creation**: InVideo has introduced an AI-powered feature that allows users to create videos using prompts, enhancing the video creation process.\n",
      "- **AI-Generated Music on YouTube**: YouTube is testing a feature that generates music remixes using AI, allowing users to experience new music formats in 30-second snippets.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [2025-01-03 09:24:54][DEBUG]: == [Researcher] Task output: - **Google to Relaunch AI Image Tool**: Google is set to relaunch a controversial tool for creating AI images after addressing previous inaccuracies that raised concerns about misinformation.\n",
      "- **AI and Data Security**: Researchers have developed a new search tool called SecureLoop that enhances the performance of complex AI tasks while ensuring data security and reducing energy consumption.\n",
      "- **OpenAI's New Tool**: OpenAI plans to launch an AI agent tool named 'Operator' in January, aimed at automating various tasks for users.\n",
      "- **AI in Video Creation**: InVideo has introduced an AI-powered feature that allows users to create videos using prompts, enhancing the video creation process.\n",
      "- **AI-Generated Music on YouTube**: YouTube is testing a feature that generates music remixes using AI, allowing users to experience new music formats in 30-second snippets.\n",
      "\n",
      "\u001b[00m\n",
      "- **Google to Relaunch AI Image Tool**: Google is set to relaunch a controversial tool for creating AI images after addressing previous inaccuracies that raised concerns about misinformation.\n",
      "- **AI and Data Security**: Researchers have developed a new search tool called SecureLoop that enhances the performance of complex AI tasks while ensuring data security and reducing energy consumption.\n",
      "- **OpenAI's New Tool**: OpenAI plans to launch an AI agent tool named 'Operator' in January, aimed at automating various tasks for users.\n",
      "- **AI in Video Creation**: InVideo has introduced an AI-powered feature that allows users to create videos using prompts, enhancing the video creation process.\n",
      "- **AI-Generated Music on YouTube**: YouTube is testing a feature that generates music remixes using AI, allowing users to experience new music formats in 30-second snippets.\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "search_tool = tavily_search\n",
    "\n",
    "research_agent = Agent(\n",
    "  role='Researcher',\n",
    "  goal='Find and summarize the latest AI news',\n",
    "  backstory=\"\"\"You're a researcher at a large company.\n",
    "  You're responsible for analyzing data and providing insights\n",
    "  to the business.\"\"\",\n",
    "  llm=llm,\n",
    "  tools=[search_tool],\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "  description='Find and summarize the latest AI news',\n",
    "  expected_output='A bullet list summary of the top 5 most important AI news',\n",
    "  agent=research_agent,\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[research_agent],\n",
    "    tasks=[task],\n",
    "    verbose=True,\n",
    "    iterations=3\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew\n",
    "# Importing crewAI tools\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "# Instantiate tools\n",
    "search_tool = DuckDuckGoSearchResults(\n",
    "    max_results=3,\n",
    ")\n",
    "\n",
    "# Create agents\n",
    "researcher = Agent(\n",
    "    role='Market Research Analyst',\n",
    "    goal='Provide up-to-date market analysis of the AI in Healthcare industry and AI in Finance industry',\n",
    "    backstory='An expert analyst with a keen eye for market trends.',\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Define tasks\n",
    "research = Task(\n",
    "    description='Research the latest trends in the AI in Healthcare industry and AI in Finance industry and provide a summary.',\n",
    "    expected_output='A summary of the top 3 trending developments with a unique perspective on their significance.',\n",
    "    agent=researcher\n",
    ")\n",
    "\n",
    "\n",
    "# Assemble a crew with planning enabled\n",
    "crew = Crew(\n",
    "    agents=[researcher],\n",
    "    tasks=[research],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    # planning=True,  # Enable planning feature\n",
    ")\n",
    "\n",
    "# Execute tasks\n",
    "crew.kickoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crew with multiple agents and multiple tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input  placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "news_research_agent = Agent(\n",
    "  role='News Researcher',\n",
    "  goal='Find and summarize the latest news',\n",
    "  backstory=\"\"\"You're a researcher at a large company.\n",
    "  You're responsible for analyzing data and providing insights\n",
    "  to the business.\"\"\",\n",
    "  llm=llm,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "stock_research_agent = Agent(\n",
    "  role='Stock Researcher',\n",
    "  goal='Find and summarize the latest information on stocks',\n",
    "  backstory=\"\"\"You're a researcher at a large company.\n",
    "  You're responsible for analyzing data and providing insights\n",
    "  to the business.\"\"\",\n",
    "  llm=llm,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "search_tool = DuckDuckGoSearchResults()\n",
    "\n",
    "# Adding placeholder for input to the task\n",
    "task_1 = Task(\n",
    "  description='Find and summarize the latest stock market news on {topic}',\n",
    "  expected_output='A bullet list summary of the important news',\n",
    "  agent=news_research_agent,\n",
    "  tools=[search_tool]\n",
    ")\n",
    "\n",
    "task_3 = Task(\n",
    "  description=\"\"\"First, identify the ticker symbol of companies (if present) present in the retrieved news. \n",
    "  Then analyse the trend of those stocks and summarize the information\"\"\",\n",
    "  expected_output='A bullet list summary of the top stocks mentioned in the news',\n",
    "  agent=stock_research_agent,\n",
    "  tools=[search_tool]\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[stock_research_agent, news_research_agent],\n",
    "    tasks=[task_1, task_3],\n",
    "    verbose=True,\n",
    "    iterations=3\n",
    ")\n",
    "\n",
    "# Adding inputs to the task\n",
    "result = crew.kickoff(inputs={'topic': 'nifty stocks'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passing context from one task to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "news_research_agent = Agent(\n",
    "  role='News Researcher',\n",
    "  goal='Find and summarize the latest news',\n",
    "  backstory=\"\"\"You're a researcher at a large company.\n",
    "  You're responsible for analyzing data and providing insights\n",
    "  to the business.\"\"\",\n",
    "  llm=llm,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "stock_research_agent = Agent(\n",
    "  role='Stock Researcher',\n",
    "  goal='Find and summarize the latest information on stocks',\n",
    "  backstory=\"\"\"You're a researcher at a large company.\n",
    "  You're responsible for analyzing data and providing insights\n",
    "  to the business.\"\"\",\n",
    "  llm=llm,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "search_tool = DuckDuckGoSearchResults()\n",
    "\n",
    "# Adding placeholder for input to the task\n",
    "task_1 = Task(\n",
    "  description='Find and summarize the latest stock market news on {topic}',\n",
    "  expected_output='A bullet list summary of the important news',\n",
    "  agent=news_research_agent,\n",
    "  tools=[search_tool]\n",
    ")\n",
    "\n",
    "task_3 = Task(\n",
    "  description=\"\"\"First, identify the ticker symbol of companies (if present) present in the retrieved news. \n",
    "  Then analyse the trend of those stocks and summarize the information\"\"\",\n",
    "  expected_output='A bullet list summary of the top stocks mentioned in the news',\n",
    "  agent=stock_research_agent,\n",
    "  tools=[search_tool],\n",
    "  # Adding context to the task\n",
    "  context=[task_1]\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[stock_research_agent, news_research_agent],\n",
    "    tasks=[task_1, task_3],\n",
    "    verbose=True,\n",
    "    iterations=3\n",
    ")\n",
    "\n",
    "# Adding inputs to the task\n",
    "result = crew.kickoff(inputs={'topic': 'top Indian IT stocks'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3_output = task_3.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(task_3_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passing task output as formatted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Stock(BaseModel):\n",
    "    ticker: str\n",
    "    trend: str\n",
    "    news: str\n",
    "    sentiment: str\n",
    "\n",
    "class Output(BaseModel):\n",
    "    stocks: List[Stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from crewai_tools import ScrapeWebsiteTool\n",
    "\n",
    "news_research_agent = Agent(\n",
    "  role='News Researcher',\n",
    "  goal='Find and summarize the latest news.',\n",
    "  backstory=\"\"\"You're a researcher at a large company.\n",
    "  You're responsible for analyzing news and providing insights to the business.\"\"\",\n",
    "  llm=llm,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "stock_research_agent = Agent(\n",
    "  role='Stock Researcher',\n",
    "  goal='Find and summarize the latest information on stocks',\n",
    "  backstory=\"\"\"You're a researcher at a large company.\n",
    "  You're responsible for analyzing stocks data and providing insights to the business.\"\"\",\n",
    "  llm=llm,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "new_search_tool = DuckDuckGoSearchResults(\n",
    "    max_results=5,\n",
    ")\n",
    "\n",
    "stock_news_search_tool = DuckDuckGoSearchResults(\n",
    "    max_results=1,\n",
    "    search_query='site:moneycontrol.com'\n",
    ")\n",
    "\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "\n",
    "# Adding placeholder for input to the task\n",
    "task_1 = Task(\n",
    "  description='Find and summarize the latest news on {topic}',\n",
    "  expected_output='A bullet list summary of the important news',\n",
    "  agent=news_research_agent,\n",
    "  tools=[new_search_tool, scrape_tool]\n",
    ")\n",
    "\n",
    "task_3 = Task(\n",
    "  description=\"\"\"First, identify the ticker symbol of companies (if present) present in the retrieved news. \n",
    "  Then analyse the trend of those stocks and summarize the information\"\"\",\n",
    "  expected_output='A bullet list summary of all the stocks mentioned in the news',\n",
    "  agent=stock_research_agent,\n",
    "  tools=[stock_news_search_tool],\n",
    "  # Task output Formatting\n",
    "  # output_pydantic=Output,\n",
    "  output_json=Output,\n",
    "  # Adding context to the task\n",
    "  context=[task_1]\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[stock_research_agent, news_research_agent],\n",
    "    tasks=[task_1, task_3],\n",
    "    verbose=True,\n",
    "    iterations=3\n",
    ")\n",
    "\n",
    "# Adding inputs to the task\n",
    "result = crew.kickoff(inputs={'topic': 'SENSEX and NIFTY'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3_output = task_3.output\n",
    "dict(task_3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_3_output.pydantic:\n",
    "    print(task_3_output.pydantic)\n",
    "elif task_3_output.json:\n",
    "    print(task_3_output.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_output = task_1.output\n",
    "dict(task_1_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Callbacks to the Task for better tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.tasks.task_output import TaskOutput\n",
    "def callback_function(output: TaskOutput):\n",
    "    # Do something after the task is completed\n",
    "    # Example: Send an email to the manager\n",
    "    print(f\"\"\"\n",
    "        Task completed!\n",
    "        Agent: {output.agent}\n",
    "        Task: {output.description}\n",
    "        Output: {output.raw}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Stock(BaseModel):\n",
    "    ticker: str\n",
    "    trend: str\n",
    "    news: str\n",
    "    sentiment: str\n",
    "\n",
    "class Output(BaseModel):\n",
    "    stocks: List[Stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from crewai_tools import ScrapeWebsiteTool\n",
    "\n",
    "news_research_agent = Agent(\n",
    "  role='News Researcher',\n",
    "  goal='Provide up-to-date market analysis.',\n",
    "  backstory='An expert analyst with a keen eye for market trends.',\n",
    "  llm=llm,\n",
    "  # verbose=True\n",
    ")\n",
    "\n",
    "stock_research_agent = Agent(\n",
    "  role='Stock Researcher',\n",
    "  goal='Provide up-to-date market analysis of companies/stocks mentioned in the news.',\n",
    "  backstory='An expert analyst with a keen eye for market trends.',\n",
    "  llm=llm,\n",
    "  # verbose=True\n",
    ")\n",
    "\n",
    "new_search_tool = DuckDuckGoSearchResults(\n",
    "    max_results=3,\n",
    ")\n",
    "\n",
    "stock_news_search_tool = DuckDuckGoSearchResults(\n",
    "    max_results=1,\n",
    ")\n",
    "\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "\n",
    "task_1 = Task(\n",
    "  description='Search, read and summarize the latest stock market news on {topic}',\n",
    "  expected_output='A bullet list summary of the important news',\n",
    "  agent=news_research_agent,\n",
    "  tools=[new_search_tool, scrape_tool],\n",
    "  # Callback function\n",
    "  callback=callback_function\n",
    ")\n",
    "\n",
    "task_3 = Task(\n",
    "  description=\"\"\"First, identify the ticker symbol of companies (if present) present in the retrieved news. \n",
    "  Then analyse the news to undertand the trend of those stocks.\"\"\",\n",
    "  expected_output='A bullet list summary of all the stocks mentioned in the news',\n",
    "  agent=stock_research_agent,\n",
    "  tools=[stock_news_search_tool],\n",
    "  # output_pydantic=Output,\n",
    "  output_json=Output,\n",
    "  context=[task_1],\n",
    "  # Callback function\n",
    "  callback=callback_function\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[stock_research_agent, news_research_agent],\n",
    "    tasks=[task_1, task_3],\n",
    "    # verbose=True,\n",
    "    iterations=3\n",
    ")\n",
    "\n",
    "# Adding inputs to the task\n",
    "result = crew.kickoff(inputs={'topic': 'NIFTY50 companies'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3.output.json_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporing the processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.tasks.task_output import TaskOutput\n",
    "def callback_function(output: TaskOutput):\n",
    "    # Do something after the task is completed\n",
    "    # Example: Send an email to the manager\n",
    "    print(f\"\"\"\n",
    "        Task completed!\n",
    "        Agent: {output.agent}\n",
    "        Task: {output.description}\n",
    "        Output: {output.raw}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Companies(BaseModel):\n",
    "    company_name: str\n",
    "    ticker: str \n",
    "    news: List[str]\n",
    "\n",
    "class Company_list(BaseModel):\n",
    "    companies: List[Companies]\n",
    "\n",
    "class Stock_trends(BaseModel):\n",
    "    ticker: str\n",
    "    trend: str = Field(description=\"The trend of the stock\", example=\"Bullish\")\n",
    "    news: List[str]\n",
    "    sentiment: str\n",
    "\n",
    "class Output(BaseModel):\n",
    "    stocks: List[Stock_trends]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from crewai_tools import ScrapeWebsiteTool, WebsiteSearchTool\n",
    "from crewai.process import Process\n",
    "\n",
    "news_search_tool = DuckDuckGoSearchResults(\n",
    "    max_results=5,\n",
    ")\n",
    "\n",
    "stock_news_search_tool = DuckDuckGoSearchResults(\n",
    "    max_results=1,\n",
    ")\n",
    "\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "web_rag_tool = WebsiteSearchTool()\n",
    "\n",
    "news_research_agent = Agent(\n",
    "  role='News Researcher',\n",
    "  goal='Read and provide up-to-date news analysis.',\n",
    "  backstory='An expert researcher with a keen eye for details.',\n",
    "  tools=[news_search_tool, scrape_tool],\n",
    "  llm=llm,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "stock_research_agent = Agent(\n",
    "  role='Stock Researcher',\n",
    "  goal='Provide up-to-date market analysis of companies/stocks.',\n",
    "  backstory='An expert analyst with a keen eye for market trends.',\n",
    "  llm=llm,\n",
    ")\n",
    "\n",
    "task_1 = Task(\n",
    "  description=\"\"\"Given an input company or sector or index: {portfolio} and date: {date},\n",
    "  Generate 1 relevant search query, search moneycontrol.com, scrape/read and summarise the news.\"\"\",\n",
    "  expected_output=\"A list of summarised news reports.\",\n",
    "  agent=news_research_agent,\n",
    "  callback=callback_function\n",
    ")\n",
    "\n",
    "task_2 = Task(\n",
    "  description=\"\"\"identify the companies present in the retrieved news. \n",
    "  Using search tool, find the ticker symbol of the companies and top news of the day.\"\"\",\n",
    "  expected_output='A list of companies, their ticker symbol and their top news of the day.',\n",
    "  tools=[stock_news_search_tool],\n",
    "  agent=news_research_agent,\n",
    "  output_json=Company_list,\n",
    "  callback=callback_function\n",
    ")\n",
    "\n",
    "task_3 = Task(\n",
    "  description=\"\"\"Analyse the news to undertand the trend and sentiment of all the companies.\"\"\",\n",
    "  expected_output='Details of all the stocks mentioned in the news',\n",
    "  agent=stock_research_agent,\n",
    "  output_pydantic=Output,\n",
    "  callback=callback_function\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[\n",
    "        news_research_agent,\n",
    "        # stock_research_agent, \n",
    "      ],\n",
    "    \n",
    "    tasks=[\n",
    "        task_1, \n",
    "        # task_2, \n",
    "        # task_3\n",
    "      ],\n",
    "    verbose=True,\n",
    "    # iterations=3,\n",
    "    # Makin the process sequential\n",
    "    # ask execution follows the predefined order in the task list, with the output of one task serving as context for the next.\n",
    "    process=Process.sequential\n",
    ")\n",
    "\n",
    "# Adding inputs to the task\n",
    "portfolio = 'NIFTY50'\n",
    "date =datetime.date.today().strftime(\"%B %d, %Y\")\n",
    "result = crew.kickoff(inputs={'portfolio': portfolio, 'date': date})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2.output.json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3.output.pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.tasks.task_output import TaskOutput\n",
    "def callback_function(output: TaskOutput):\n",
    "    # Do something after the task is completed\n",
    "    # Example: Send an email to the manager\n",
    "    print(f\"\"\"\n",
    "        Task completed!\n",
    "        Agent: {output.agent}\n",
    "        Task: {output.description}\n",
    "        Output: {output.raw}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class News(BaseModel):\n",
    "    company_name: str\n",
    "    news: str\n",
    "\n",
    "class Stock_news(BaseModel):\n",
    "    news: List[News]\n",
    "\n",
    "class Companies(BaseModel):\n",
    "    company_name: str\n",
    "    ticker: str\n",
    "\n",
    "class Company_list(BaseModel):\n",
    "    companies: List[Companies]\n",
    "\n",
    "class Stock_trends(BaseModel):\n",
    "    ticker: str\n",
    "    trend: str\n",
    "    news: List[str]\n",
    "    sentiment: str\n",
    "\n",
    "class Output(BaseModel):\n",
    "    stocks: List[Stock_trends]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from crewai_tools import ScrapeWebsiteTool\n",
    "from crewai.process import Process\n",
    "\n",
    "news_search_tool = DuckDuckGoSearchResults(\n",
    "    max_results=3,\n",
    ")\n",
    "\n",
    "stock_news_search_tool = DuckDuckGoSearchResults(\n",
    "    max_results=1,\n",
    ")\n",
    "\n",
    "scrape_tool = ScrapeWebsiteTool()\n",
    "\n",
    "news_research_agent = Agent(\n",
    "  role='News Researcher',\n",
    "  goal= \"First, Generate the most relevant search query. Then efficiently retrieve accurate and relevant search results for each query.\",\n",
    "  backstory= \"\"\"I am a dedicated Researcher with a deep understanding of information retrieval and analysis. \n",
    "                My expertise lies in transforming a user's query into the most relevant search questions and retrieving results.\"\"\",\n",
    "  tools=[news_search_tool, news_search_tool],\n",
    "  llm=llm,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "news_aggregator_agent = Agent(\n",
    "  role='News Aggregator',\n",
    "  goal= \"Aggregate and summarize the news from the search results.\",\n",
    "  backstory= \"\"\"I am a dedicated News Aggregator with a deep understanding of stock market and business. \n",
    "                My expertise lies in transforming news into ationable insights.\"\"\",   \n",
    "  llm=llm,\n",
    ")\n",
    "\n",
    "stock_research_agent = Agent(\n",
    "  role='Stock Researcher',\n",
    "  goal='Provide up-to-date market analysis of companies/stocks.',\n",
    "  backstory='An expert analyst with a keen eye for market trends.',\n",
    "  llm=llm,\n",
    ")\n",
    "\n",
    "task_1 = Task(\n",
    "  description=\"\"\"Given a protfolio of companies: {portfolio}, first identify all the company names.\n",
    "  Then generate search query for each company in the portfolio, scrape the news from the search results.\n",
    "  Finally compile all the search results and return the company name and the news for each company.\"\"\",\n",
    "  expected_output=\"All the companies mentoined in the portfolio and summary of retrieved news reports.\",\n",
    "  agent=news_research_agent,\n",
    "  output_json=Stock_news,\n",
    "  # callback=callback_function\n",
    ")\n",
    "\n",
    "task_2 = Task(\n",
    "  description=\"\"\"identify the companies present in the retrieved news. \n",
    "  Using search tool, find the ticker symbol of the companies.\"\"\",\n",
    "  expected_output='A list of companies and their ticker symbol.',\n",
    "  tools=[stock_news_search_tool],\n",
    "  agent=news_research_agent,\n",
    "  output_json=Company_list,\n",
    "  callback=callback_function\n",
    ")\n",
    "\n",
    "task_3 = Task(\n",
    "  description=\"\"\"Analyse the news to undertand the trend and sentiment of all the companies.\"\"\",\n",
    "  expected_output='Details of all the stocks mentioned in the news',\n",
    "  agent=stock_research_agent,\n",
    "  output_pydantic=Output,\n",
    "  context=[task_1, task_2],\n",
    "  callback=callback_function\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[\n",
    "        news_research_agent,\n",
    "        news_aggregator_agent,\n",
    "        # stock_research_agent, \n",
    "      ],\n",
    "    \n",
    "    tasks=[\n",
    "        task_1, \n",
    "        # task_2, \n",
    "        # task_3\n",
    "      ],\n",
    "    verbose=True,\n",
    "    # iterations=3,\n",
    "    # Makin the process sequential\n",
    "    # ask execution follows the predefined order in the task list, with the output of one task serving as context for the next.\n",
    "    process=Process.hierarchical\n",
    ")\n",
    "\n",
    "# Adding inputs to the task\n",
    "portfolio = ['IT Stocks']\n",
    "result = crew.kickoff(inputs={'portfolio': str(', '.join(portfolio))})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1.output.json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2.output.json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3.output.pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
