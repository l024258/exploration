{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/L024258/lilly_work/github-copilot/exploration/notebooks/..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory and add the parent directory to the Python path\n",
    "current_working_directory = os.getcwd()\n",
    "print(os.path.join(current_working_directory, \"..\"))\n",
    "sys.path.append(os.path.join(current_working_directory, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import AutoConfig\n",
    "config = AutoConfig(search_path='./../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = config('OPENAI_API_KEY')\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = config('AZURE_ENDPOINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions, Models, and Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from models.llm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_generator(topic):\n",
    "    \"This function will return a joke based on the topic provided\"\n",
    "    model = LLM('gpt-4')\n",
    "    llm = model.load_model()\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Write a short joke on {topic}\"\n",
    "    )\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt | llm | output_parser\n",
    "    return chain.invoke({\"topic\":topic})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = joke_generator(\"Artificial Intelligence\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_generator(topic):\n",
    "    \"This function will return a poem based on the topic provided\"\n",
    "    model = LLM('gpt-4')\n",
    "    llm = model.load_model()\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Write a short poem on {topic}\"\n",
    "    )\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt | llm | output_parser\n",
    "    return chain.invoke({\"topic\":topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = poem_generator(\"Artificial Intelligence\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI functon format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions =[\n",
    "    {\n",
    "      \"name\": \"joke_generator\",\n",
    "      \"description\": \"Generates a joke based on the topic provided\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"topic\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The topic to get the joke for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"topic\"]\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"poem_generator\",\n",
    "      \"description\": \"Generates a poem based on the topic provided\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"topic\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The topic to get the poem for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"topic\"]\n",
    "      }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attaching functions with model invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a smart and intelligent AI Assistant.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.llm import LLM\n",
    "\n",
    "model = LLM('gpt-4')\n",
    "gpt4 = model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4.invoke(input=\"poem on Artificial Intelligence\", functions=functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** With this approach, it is required to attach functions with everytime model is invoked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binding model with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "gpt4 = AzureChatOpenAI(\n",
    "                openai_api_version=config('AZURE_CHAT_OPENAI_API_VERSION'),\n",
    "                azure_deployment=config('AZURE_GPT4_CHAT_OPENAI_DEPLOYMENT'),\n",
    "                temperature=0,\n",
    "                max_tokens=1024\n",
    "            ).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = messages | gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"joke about Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"poem on Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain_community.tools.pubmed.tool import PubmedQueryRun\n",
    "\n",
    "arxiv_search = ArxivQueryRun()\n",
    "pubmed_search = PubmedQueryRun()\n",
    "\n",
    "tools = [arxiv_search, pubmed_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_search.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/L024258/lilly_work/github-copilot/exploration/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published: 2024-05-23\n",
      "Title: Exploring Prosocial Irrationality for LLM Agents: A Social Cognition View\n",
      "Authors: Xuan Liu, Jie Zhang, Song Guo, Haoyang Shang, Chengxu Yang, Quanyan Zhu\n",
      "Summary: Large language models (LLMs) have been shown to face hallucination issues due\n",
      "to the data they trained on often containing human bias; whether this is\n",
      "reflected in the decision-making process of LLM agents remains under-explored.\n",
      "As LLM Agents are increasingly employed in intricate social environments, a\n",
      "pressing and natural question emerges: Can LLM Agents leverage hallucinations\n",
      "to mirror human cognitive biases, thus exhibiting irrational social\n",
      "intelligence? In this paper, we probe the irrational behavior among\n",
      "contemporary LLM agents by melding practical social science experiments with\n",
      "theoretical insights. Specifically, We propose CogMir, an open-ended Multi-LLM\n",
      "Agents framework that utilizes hallucination properties to assess and enhance\n",
      "LLM Agents' social intelligence through cognitive biases. Experimental results\n",
      "on CogMir subsets show that LLM Agents and humans exhibit high consistency in\n",
      "irrational and prosocial decision-making under uncertain conditions,\n",
      "underscoring the prosociality of LLM Agents as social entities, and\n",
      "highlighting the significance of hallucination properties. Additionally, CogMir\n",
      "framework demonstrates its potential as a valuable platform for encouraging\n",
      "more research into the social intelligence of LLM Agents.\n",
      "\n",
      "Published: 2024-08-05\n",
      "Title: From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future\n",
      "Authors: Haolin Jin, Linghan Huang, Haipeng Cai, Jun Yan, Bo Li, Huaming Chen\n",
      "Summary: With the rise of large language models (LLMs), researchers are increasingly\n",
      "exploring their applications in var ious vertical domains, such as software\n",
      "engineering. LLMs have achieved remarkable success in areas including code\n",
      "generation and vulnerability detection. However, they also exhibit numerous\n",
      "limitations and shortcomings. LLM-based agents, a novel tech nology with the\n",
      "potential for Artificial General Intelligence (AGI), combine LLMs as the core\n",
      "for decision-making and action-taking, addressing some of the inherent\n",
      "limitations of LLMs such as lack of autonomy and self-improvement. Despite\n",
      "numerous studies and surveys exploring the possibility of using LLMs in\n",
      "software engineering, it lacks a clear distinction between LLMs and LLM based\n",
      "agents. It is still in its early stage for a unified standard and benchmarking\n",
      "to qualify an LLM solution as an LLM-based agent in its domain. In this survey,\n",
      "we broadly investigate the current practice and solutions for LLMs and\n",
      "LLM-based agents for software engineering. In particular we summarise six key\n",
      "topics: requirement engineering, code generation, autonomous decision-making,\n",
      "software design, test generation, and software maintenance. We review and\n",
      "differentiate the work of LLMs and LLM-based agents from these six topics,\n",
      "examining their differences and similarities in tasks, benchmarks, and\n",
      "evaluation metrics. Finally, we discuss the models and benchmarks used,\n",
      "providing a comprehensive analysis of their applications and effectiveness in\n",
      "software engineering. We anticipate this work will shed some lights on pushing\n",
      "the boundaries of LLM-based agents in software engineering for future research.\n",
      "\n",
      "Published: 2024-07-11\n",
      "Title: EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms\n",
      "Authors: Siyu Yuan, Kaitao Song, Jiangjie Chen, Xu Tan, Dongsheng Li, Deqing Yang\n",
      "Summary: The rise of powerful large language models (LLMs) has spurred a new trend in\n",
      "building LLM-based autonomous agents for solving complex tasks, especially\n",
      "multi-agent systems. Despite the remarkable progress, we notice that existing\n",
      "works are heavily dependent on human-designed frameworks, which greatly limits\n",
      "the functional scope and scalability of agent systems. How to automatically\n",
      "extend the specialized agent to multi-agent systems to improve task-solving\n"
     ]
    }
   ],
   "source": [
    "print(arxiv_search({\"query\": \"LLM Agents\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/L024258/lilly_work/github-copilot/exploration/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.3.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'arxiv',\n",
       " 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'query': {'description': 'search query to look up',\n",
       "    'type': 'string'}},\n",
       "  'required': ['query']}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "format_tool_to_openai_function(arxiv_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.llm import LLM\n",
    "\n",
    "model = LLM('gpt-4')\n",
    "gpt4 = model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    format_tool_to_openai_function(f) for f in [\n",
    "        arxiv_search, pubmed_search\n",
    "    ]\n",
    "]\n",
    "model = gpt4.bind(function=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv_search, pubmed_search]\n",
    "tools_model = gpt4.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mdnjeXnlzttjUQyTNtvvBDfd', 'function': {'arguments': '{\\n  \"query\": \"survey on LLM Agents\"\\n}', 'name': 'arxiv'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 162, 'total_tokens': 181}, 'model_name': 'gpt-4-32k', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-d395f8a7-8177-4d1c-8040-66eeb114886e-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'survey on LLM Agents'}, 'id': 'call_mdnjeXnlzttjUQyTNtvvBDfd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 19, 'total_tokens': 181})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_model.invoke(\"survey on LLM Agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | tools_model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\": \"survey on LLM Agents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': ''}, log='')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
