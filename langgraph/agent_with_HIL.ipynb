{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/L024258/lilly_work/github-copilot/exploration/langgraph/..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory and add the parent directory to the Python path\n",
    "current_working_directory = os.getcwd()\n",
    "print(os.path.join(current_working_directory, \"..\"))\n",
    "sys.path.append(os.path.join(current_working_directory, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "import operator\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command, interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    intermediate_step: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain_community.tools.pubmed.tool import PubmedQueryRun\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "pubmed_search = PubmedQueryRun()\n",
    "arxiv_search = ArxivQueryRun()\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "tools = [arxiv_search, pubmed_search, tavily_tool]\n",
    "# tools = [arxiv_search, pubmed_search]\n",
    "# tools = [arxiv_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def request_user_feedback(query: str) -> str:\n",
    "    \"\"\"Request assistance or feedback from a human.\"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]\n",
    "\n",
    "tools.append(request_user_feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.llm import LLM\n",
    "\n",
    "model = LLM('gpt-4o-mini')\n",
    "llm = model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "def research_agent(data):\n",
    "    print(\"----research node----\")\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI research assistant chatbot,\"\n",
    "                \" Provided a user query generate 2 more similar queries and search for relevant results.\"\n",
    "                \" Use the appropriate search tools to progress towards finding the relevant results.\"\n",
    "                \" Once you have the relevant search results, take user feedback.\"\n",
    "                \" If user says No/no (indicating No more searching), summarise the search results to answer the user query\"\n",
    "                \"\\nYou have access to the following search tools: {tool_names}.\"\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\\nUser Query: {input}\"\n",
    "            ),\n",
    "            \n",
    "            MessagesPlaceholder(variable_name=\"intermediate_step\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    agent = prompt | llm.bind_tools(tools)\n",
    "    result = agent.invoke(data)\n",
    "    return {'agent_outcome': [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12d737410>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"research\", research_agent)\n",
    "workflow.set_entry_point(\"research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12d737410>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class BasicToolNode:\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        print(\"----tool calling----\")\n",
    "        message = inputs[\"agent_outcome\"][-1]\n",
    "\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            print(f\"---- Calling {tool_call['name']} with args: {tool_call['args']} ----\")\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return {\n",
    "                \"agent_outcome\": outputs,\n",
    "                \"intermediate_step\": [str(outputs)]\n",
    "            }\n",
    "\n",
    "tool_node = BasicToolNode(tools=tools)\n",
    "workflow.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(\n",
    "    state: AgentState,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    print(\"----router----\")\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif agent_outcome := state.get(\"agent_outcome\", []):\n",
    "        ai_message = agent_outcome[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12d737410>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_conditional_edges(\n",
    "    \"research\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", END: END}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12d737410>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"tools\", \"research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Human in the Loop (HIL)\n",
    "\n",
    "- `interrupt_before (Optional[Union[All, Sequence[str]]], default: None )` – Nodes to interrupt before, defaults to all nodes in the graph.\n",
    "- `interrupt_after (Optional[Union[All, Sequence[str]]], default: None )` – Nodes to interrupt after, defaults to all nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = workflow.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_after=[\"research\"],)\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Starting Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the recent papers on Small Language Models?\n",
      "----research node----\n",
      "----router----\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_ONsYgXJ7vt0DmB2lcWWd3jKY)\n",
      " Call ID: call_ONsYgXJ7vt0DmB2lcWWd3jKY\n",
      "  Args:\n",
      "    query: Small Language Models\n",
      "  tavily_search_results_json (call_GLJyBrkQz0LDQNp3GTcIdAwC)\n",
      " Call ID: call_GLJyBrkQz0LDQNp3GTcIdAwC\n",
      "  Args:\n",
      "    query: recent papers on Small Language Models\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"input\": \"What are the recent papers on Small Language Models?\",\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"123\",\n",
    "    }\n",
    "}\n",
    "\n",
    "state = AgentState(**inputs)\n",
    "events = app.stream(input=state, config=config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    try:\n",
    "        for msg in event[\"agent_outcome\"]:\n",
    "            msg.pretty_print()\n",
    "    except Exception:\n",
    "        HumanMessage(event[\"input\"]).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution got stopped after the tools call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'input': 'What are the recent papers on Small Language Models?', 'agent_outcome': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ONsYgXJ7vt0DmB2lcWWd3jKY', 'function': {'arguments': '{\"query\": \"Small Language Models\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_GLJyBrkQz0LDQNp3GTcIdAwC', 'function': {'arguments': '{\"query\": \"recent papers on Small Language Models\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 345, 'total_tokens': 400, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5154047bf2', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-1eb29069-00aa-4eec-bcbd-e16b9791e870-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'Small Language Models'}, 'id': 'call_ONsYgXJ7vt0DmB2lcWWd3jKY', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'recent papers on Small Language Models'}, 'id': 'call_GLJyBrkQz0LDQNp3GTcIdAwC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 345, 'output_tokens': 55, 'total_tokens': 400})], 'intermediate_step': []}, next=('tools',), config={'configurable': {'thread_id': '123', 'checkpoint_ns': '', 'checkpoint_id': '1efd9448-9690-61fc-8001-f9c591e6371f'}}, metadata={'source': 'loop', 'writes': {'research': {'agent_outcome': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ONsYgXJ7vt0DmB2lcWWd3jKY', 'function': {'arguments': '{\"query\": \"Small Language Models\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_GLJyBrkQz0LDQNp3GTcIdAwC', 'function': {'arguments': '{\"query\": \"recent papers on Small Language Models\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 345, 'total_tokens': 400, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5154047bf2', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-1eb29069-00aa-4eec-bcbd-e16b9791e870-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'Small Language Models'}, 'id': 'call_ONsYgXJ7vt0DmB2lcWWd3jKY', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'recent papers on Small Language Models'}, 'id': 'call_GLJyBrkQz0LDQNp3GTcIdAwC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 345, 'output_tokens': 55, 'total_tokens': 400})]}}, 'thread_id': '123', 'step': 1, 'parents': {}}, created_at='2025-01-23T04:43:05.813842+00:00', parent_config={'configurable': {'thread_id': '123', 'checkpoint_ns': '', 'checkpoint_id': '1efd9448-4fc5-66a0-8000-764895c8b04d'}}, tasks=(PregelTask(id='8fa190ca-3b75-12f6-aec0-c61b71864979', name='tools', path=('__pregel_pull', 'tools'), error=None, interrupts=(), state=None, result=None),))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = app.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ONsYgXJ7vt0DmB2lcWWd3jKY', 'function': {'arguments': '{\"query\": \"Small Language Models\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_GLJyBrkQz0LDQNp3GTcIdAwC', 'function': {'arguments': '{\"query\": \"recent papers on Small Language Models\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 345, 'total_tokens': 400, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5154047bf2', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-1eb29069-00aa-4eec-bcbd-e16b9791e870-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'Small Language Models'}, 'id': 'call_ONsYgXJ7vt0DmB2lcWWd3jKY', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'recent papers on Small Language Models'}, 'id': 'call_GLJyBrkQz0LDQNp3GTcIdAwC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 345, 'output_tokens': 55, 'total_tokens': 400})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.values[\"agent_outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_ONsYgXJ7vt0DmB2lcWWd3jKY)\n",
      " Call ID: call_ONsYgXJ7vt0DmB2lcWWd3jKY\n",
      "  Args:\n",
      "    query: Small Language Models\n",
      "  tavily_search_results_json (call_GLJyBrkQz0LDQNp3GTcIdAwC)\n",
      " Call ID: call_GLJyBrkQz0LDQNp3GTcIdAwC\n",
      "  Args:\n",
      "    query: recent papers on Small Language Models\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----tool calling----\n",
      "---- Calling arxiv with args: {'query': 'Small Language Models'} ----\n",
      "---- Calling tavily_search_results_json with args: {'query': 'recent papers on Small Language Models'} ----\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "\"Published: 2022-01-26\\nTitle: An Assessment of the Impact of OCR Noise on Language Models\\nAuthors: Konstantin Todorov, Giovanni Colavizza\\nSummary: Neural language models are the backbone of modern-day natural language\\nprocessing applications. Their use on textual heritage collections which have\\nundergone Optical Character Recognition (OCR) is therefore also increasing.\\nNevertheless, our understanding of the impact OCR noise could have on language\\nmodels is still limited. We perform an assessment of the impact OCR noise has\\non a variety of language models, using data in Dutch, English, French and\\nGerman. We find that OCR noise poses a significant obstacle to language\\nmodelling, with language models increasingly diverging from their noiseless\\ntargets as OCR quality lowers. In the presence of small corpora, simpler models\\nincluding PPMI and Word2Vec consistently outperform transformer-based models in\\nthis respect.\\n\\nPublished: 2024-12-09\\nTitle: Small Languages, Big Models: A Study of Continual Training on Languages of Norway\\nAuthors: David Samuel, Vladislav Mikhailov, Erik Velldal, Lilja \\u00d8vrelid, Lucas Georges Gabriel Charpentier, Andrey Kutuzov\\nSummary: Training large language models requires vast amounts of data, posing a\\nchallenge for less widely spoken languages like Norwegian and even more so for\\ntruly low-resource languages like S\\\\'ami. To address this issue, we present a\\nnovel three-stage continual training approach. We also experiment with\\ncombining causal and masked language modeling to get more flexible models.\\nBased on our findings, we train, evaluate, and openly release a new large\\ngenerative language model for Norwegian Bokm\\\\r{a}l, Nynorsk, and Northern\\nS\\\\'ami with 11.4 billion parameters: NorMistral-11B.\\n\\nPublished: 2024-09-26\\nTitle: Enhancing elusive clues in knowledge learning by contrasting attention of language models\\nAuthors: Jian Gao, Xiao Zhang, Ji Wu, Miao Li\\nSummary: Causal language models acquire vast amount of knowledge from general text\\ncorpus during pretraining, but the efficiency of knowledge learning is known to\\nbe unsatisfactory, especially when learning from knowledge-dense and\\nsmall-sized corpora. The deficiency can come from long-distance dependencies\\nwhich are hard to capture by language models, and overfitting to co-occurrence\\npatterns and distracting clues in the training text. To address these issues,\\nthe paper proposes a method to enhance knowledge learning during language model\\npretraining, by enhancing elusive but important clues in text discovered by the\\nlanguage model themselves. We found that larger language models pay more\\nattention to non-obvious but important clues, which are often overlooked by\\nsmaller language models. Therefore, we can identify these clues by contrasting\\nthe attention weights of large and small language models. We use the identified\\nclues as a guide to perform token-dropout data augmentation on the training\\ntext, and observed a significant boost in both small and large models'\\nperformance in fact memorization. This shows that the behavior contrast between\\nmore and less-performant language models contains important clues for knowledge\\nlearning, and it can be ``amplified\\\" for a straight-forward improvement in\\nknowledge learning efficiency.\"\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://paperswithcode.com/paper/small-language-models-survey-measurements-and\", \"content\": \"Small Language Models: Survey, Measurements, and Insights | Papers With Code Subscribe to the PwC Newsletter Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. Add a new code entry for this paper Remove a code repository from this paper Add a task. Add a task Add a method Edit Datasets Add or remove datasets introduced in this paper: Add or remove other datasets used in this paper: Paper introduces a new dataset? Add a new dataset here Focusing on transformer-based, decoder-only language models with 100M-5B parameters, we survey 59 state-of-the-art open-source SLMs, analyzing their technical innovations across three axes: architectures, training datasets, and training algorithms. Benchmarking Decoder In-Context Learning Language Modelling Large Language Model Survey No methods listed for this paper.\"}, {\"url\": \"https://paperswithcode.com/paper/a-survey-of-small-language-models\", \"content\": \"Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. ... Small Language Models (SLMs) have become increasingly important due to their efficiency and performance to perform various language tasks with minimal computational resources, making them ideal for various settings including on\"}, {\"url\": \"https://arxiv.org/abs/2409.15790\", \"content\": \"[2409.15790] Small Language Models: Survey, Measurements, and Insights > cs > arXiv:2409.15790 arXiv:2409.15790 (cs) Title:Small Language Models: Survey, Measurements, and Insights View a PDF of the paper titled Small Language Models: Survey, Measurements, and Insights, by Zhenyan Lu and 7 other authors Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) arXiv:2409.15790 [cs.CL] (or arXiv:2409.15790v1 [cs.CL] for this version) View a PDF of the paper titled Small Language Models: Survey, Measurements, and Insights, by Zhenyan Lu and 7 other authors cs cs.AI Bibliographic and Citation Tools Bibliographic Explorer Toggle Litmaps Toggle scite.ai Toggle Links to Code Toggle DagsHub Toggle GotitPub Toggle Links to Code Toggle ScienceCast Toggle Replicate Toggle Spaces Toggle Spaces Toggle Connected Papers Toggle Core recommender toggle\"}, {\"url\": \"https://arxiv.org/abs/2411.03350\", \"content\": \"[2411.03350] A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness Title:A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness View a PDF of the paper titled A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness, by Fali Wang and 13 other authors View a PDF of the paper titled A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness, by Fali Wang and 13 other authors Links to Code Toggle Links to Code Toggle\"}, {\"url\": \"https://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-141.html\", \"content\": \"However, there has not been as much work on smaller language models that can potentially solve tasks where it would be inefficient to run a full LLM at scale. In this paper, we explore Small Language Models (SLMs) and how we can make them more efficient at the edge without sacrificing performance.\"}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----research node----\n",
      "----router----\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_M05w8phoFb93IkFzckBnIZIG)\n",
      " Call ID: call_M05w8phoFb93IkFzckBnIZIG\n",
      "  Args:\n",
      "    query: Small Language Models\n",
      "  tavily_search_results_json (call_QpqVBUBPDj9vYxwsSGTmeHMZ)\n",
      " Call ID: call_QpqVBUBPDj9vYxwsSGTmeHMZ\n",
      "  Args:\n",
      "    query: recent papers on Small Language Models\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "events = app.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "for event in events:\n",
    "    try:\n",
    "        for msg in event[\"agent_outcome\"]:\n",
    "            msg.pretty_print()\n",
    "    except Exception as e:\n",
    "        HumanMessage(event[\"input\"]).pretty_print()\n",
    "    print(\"-----\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'input': 'What are the recent papers on Small Language Models?', 'agent_outcome': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_M05w8phoFb93IkFzckBnIZIG', 'function': {'arguments': '{\"query\": \"Small Language Models\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_QpqVBUBPDj9vYxwsSGTmeHMZ', 'function': {'arguments': '{\"query\": \"recent papers on Small Language Models\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 1976, 'total_tokens': 2031, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5154047bf2', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-c769d9e3-5cdf-467f-8aff-50b480f404c1-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'Small Language Models'}, 'id': 'call_M05w8phoFb93IkFzckBnIZIG', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'recent papers on Small Language Models'}, 'id': 'call_QpqVBUBPDj9vYxwsSGTmeHMZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1976, 'output_tokens': 55, 'total_tokens': 2031})], 'intermediate_step': ['[ToolMessage(content=\\'\"Published: 2022-01-26\\\\\\\\nTitle: An Assessment of the Impact of OCR Noise on Language Models\\\\\\\\nAuthors: Konstantin Todorov, Giovanni Colavizza\\\\\\\\nSummary: Neural language models are the backbone of modern-day natural language\\\\\\\\nprocessing applications. Their use on textual heritage collections which have\\\\\\\\nundergone Optical Character Recognition (OCR) is therefore also increasing.\\\\\\\\nNevertheless, our understanding of the impact OCR noise could have on language\\\\\\\\nmodels is still limited. We perform an assessment of the impact OCR noise has\\\\\\\\non a variety of language models, using data in Dutch, English, French and\\\\\\\\nGerman. We find that OCR noise poses a significant obstacle to language\\\\\\\\nmodelling, with language models increasingly diverging from their noiseless\\\\\\\\ntargets as OCR quality lowers. In the presence of small corpora, simpler models\\\\\\\\nincluding PPMI and Word2Vec consistently outperform transformer-based models in\\\\\\\\nthis respect.\\\\\\\\n\\\\\\\\nPublished: 2024-12-09\\\\\\\\nTitle: Small Languages, Big Models: A Study of Continual Training on Languages of Norway\\\\\\\\nAuthors: David Samuel, Vladislav Mikhailov, Erik Velldal, Lilja \\\\\\\\u00d8vrelid, Lucas Georges Gabriel Charpentier, Andrey Kutuzov\\\\\\\\nSummary: Training large language models requires vast amounts of data, posing a\\\\\\\\nchallenge for less widely spoken languages like Norwegian and even more so for\\\\\\\\ntruly low-resource languages like S\\\\\\\\\\\\\\\\\\\\\\'ami. To address this issue, we present a\\\\\\\\nnovel three-stage continual training approach. We also experiment with\\\\\\\\ncombining causal and masked language modeling to get more flexible models.\\\\\\\\nBased on our findings, we train, evaluate, and openly release a new large\\\\\\\\ngenerative language model for Norwegian Bokm\\\\\\\\\\\\\\\\r{a}l, Nynorsk, and Northern\\\\\\\\nS\\\\\\\\\\\\\\\\\\\\\\'ami with 11.4 billion parameters: NorMistral-11B.\\\\\\\\n\\\\\\\\nPublished: 2024-09-26\\\\\\\\nTitle: Enhancing elusive clues in knowledge learning by contrasting attention of language models\\\\\\\\nAuthors: Jian Gao, Xiao Zhang, Ji Wu, Miao Li\\\\\\\\nSummary: Causal language models acquire vast amount of knowledge from general text\\\\\\\\ncorpus during pretraining, but the efficiency of knowledge learning is known to\\\\\\\\nbe unsatisfactory, especially when learning from knowledge-dense and\\\\\\\\nsmall-sized corpora. The deficiency can come from long-distance dependencies\\\\\\\\nwhich are hard to capture by language models, and overfitting to co-occurrence\\\\\\\\npatterns and distracting clues in the training text. To address these issues,\\\\\\\\nthe paper proposes a method to enhance knowledge learning during language model\\\\\\\\npretraining, by enhancing elusive but important clues in text discovered by the\\\\\\\\nlanguage model themselves. We found that larger language models pay more\\\\\\\\nattention to non-obvious but important clues, which are often overlooked by\\\\\\\\nsmaller language models. Therefore, we can identify these clues by contrasting\\\\\\\\nthe attention weights of large and small language models. We use the identified\\\\\\\\nclues as a guide to perform token-dropout data augmentation on the training\\\\\\\\ntext, and observed a significant boost in both small and large models\\\\\\'\\\\\\\\nperformance in fact memorization. This shows that the behavior contrast between\\\\\\\\nmore and less-performant language models contains important clues for knowledge\\\\\\\\nlearning, and it can be ``amplified\\\\\\\\\" for a straight-forward improvement in\\\\\\\\nknowledge learning efficiency.\"\\', name=\\'arxiv\\', tool_call_id=\\'call_ONsYgXJ7vt0DmB2lcWWd3jKY\\'), ToolMessage(content=\\'[{\"url\": \"https://paperswithcode.com/paper/small-language-models-survey-measurements-and\", \"content\": \"Small Language Models: Survey, Measurements, and Insights | Papers With Code Subscribe to the PwC Newsletter Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. Add a new code entry for this paper Remove a code repository from this paper Add a task. Add a task Add a method Edit Datasets Add or remove datasets introduced in this paper: Add or remove other datasets used in this paper: Paper introduces a new dataset? Add a new dataset here Focusing on transformer-based, decoder-only language models with 100M-5B parameters, we survey 59 state-of-the-art open-source SLMs, analyzing their technical innovations across three axes: architectures, training datasets, and training algorithms. Benchmarking Decoder In-Context Learning Language Modelling Large Language Model Survey No methods listed for this paper.\"}, {\"url\": \"https://paperswithcode.com/paper/a-survey-of-small-language-models\", \"content\": \"Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. ... Small Language Models (SLMs) have become increasingly important due to their efficiency and performance to perform various language tasks with minimal computational resources, making them ideal for various settings including on\"}, {\"url\": \"https://arxiv.org/abs/2409.15790\", \"content\": \"[2409.15790] Small Language Models: Survey, Measurements, and Insights > cs > arXiv:2409.15790 arXiv:2409.15790 (cs) Title:Small Language Models: Survey, Measurements, and Insights View a PDF of the paper titled Small Language Models: Survey, Measurements, and Insights, by Zhenyan Lu and 7 other authors Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) arXiv:2409.15790 [cs.CL] (or arXiv:2409.15790v1 [cs.CL] for this version) View a PDF of the paper titled Small Language Models: Survey, Measurements, and Insights, by Zhenyan Lu and 7 other authors cs cs.AI Bibliographic and Citation Tools Bibliographic Explorer Toggle Litmaps Toggle scite.ai Toggle Links to Code Toggle DagsHub Toggle GotitPub Toggle Links to Code Toggle ScienceCast Toggle Replicate Toggle Spaces Toggle Spaces Toggle Connected Papers Toggle Core recommender toggle\"}, {\"url\": \"https://arxiv.org/abs/2411.03350\", \"content\": \"[2411.03350] A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness Title:A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness View a PDF of the paper titled A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness, by Fali Wang and 13 other authors View a PDF of the paper titled A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness, by Fali Wang and 13 other authors Links to Code Toggle Links to Code Toggle\"}, {\"url\": \"https://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-141.html\", \"content\": \"However, there has not been as much work on smaller language models that can potentially solve tasks where it would be inefficient to run a full LLM at scale. In this paper, we explore Small Language Models (SLMs) and how we can make them more efficient at the edge without sacrificing performance.\"}]\\', name=\\'tavily_search_results_json\\', tool_call_id=\\'call_GLJyBrkQz0LDQNp3GTcIdAwC\\')]']}, next=('tools',), config={'configurable': {'thread_id': '123', 'checkpoint_ns': '', 'checkpoint_id': '1efd944b-16bf-6c86-8003-3433de8c6306'}}, metadata={'source': 'loop', 'writes': {'research': {'agent_outcome': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_M05w8phoFb93IkFzckBnIZIG', 'function': {'arguments': '{\"query\": \"Small Language Models\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_QpqVBUBPDj9vYxwsSGTmeHMZ', 'function': {'arguments': '{\"query\": \"recent papers on Small Language Models\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 1976, 'total_tokens': 2031, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5154047bf2', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-c769d9e3-5cdf-467f-8aff-50b480f404c1-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'Small Language Models'}, 'id': 'call_M05w8phoFb93IkFzckBnIZIG', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'recent papers on Small Language Models'}, 'id': 'call_QpqVBUBPDj9vYxwsSGTmeHMZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1976, 'output_tokens': 55, 'total_tokens': 2031})]}}, 'thread_id': '123', 'step': 3, 'parents': {}}, created_at='2025-01-23T04:44:12.942200+00:00', parent_config={'configurable': {'thread_id': '123', 'checkpoint_ns': '', 'checkpoint_id': '1efd944a-e29e-686c-8002-a340b746eaa7'}}, tasks=(PregelTask(id='fc0a982a-4bac-b210-dc5c-058b238aac2b', name='tools', path=('__pregel_pull', 'tools'), error=None, interrupts=(), state=None, result=None),))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = app.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_M05w8phoFb93IkFzckBnIZIG', 'function': {'arguments': '{\"query\": \"Small Language Models\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_QpqVBUBPDj9vYxwsSGTmeHMZ', 'function': {'arguments': '{\"query\": \"recent papers on Small Language Models\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 1976, 'total_tokens': 2031, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5154047bf2', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-c769d9e3-5cdf-467f-8aff-50b480f404c1-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'Small Language Models'}, 'id': 'call_M05w8phoFb93IkFzckBnIZIG', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'recent papers on Small Language Models'}, 'id': 'call_QpqVBUBPDj9vYxwsSGTmeHMZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1976, 'output_tokens': 55, 'total_tokens': 2031})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.values[\"agent_outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----tool calling----\n",
      "---- Calling arxiv with args: {'query': 'Small Language Models'} ----\n",
      "---- Calling tavily_search_results_json with args: {'query': 'recent papers on Small Language Models'} ----\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "\"Published: 2022-01-26\\nTitle: An Assessment of the Impact of OCR Noise on Language Models\\nAuthors: Konstantin Todorov, Giovanni Colavizza\\nSummary: Neural language models are the backbone of modern-day natural language\\nprocessing applications. Their use on textual heritage collections which have\\nundergone Optical Character Recognition (OCR) is therefore also increasing.\\nNevertheless, our understanding of the impact OCR noise could have on language\\nmodels is still limited. We perform an assessment of the impact OCR noise has\\non a variety of language models, using data in Dutch, English, French and\\nGerman. We find that OCR noise poses a significant obstacle to language\\nmodelling, with language models increasingly diverging from their noiseless\\ntargets as OCR quality lowers. In the presence of small corpora, simpler models\\nincluding PPMI and Word2Vec consistently outperform transformer-based models in\\nthis respect.\\n\\nPublished: 2024-12-09\\nTitle: Small Languages, Big Models: A Study of Continual Training on Languages of Norway\\nAuthors: David Samuel, Vladislav Mikhailov, Erik Velldal, Lilja \\u00d8vrelid, Lucas Georges Gabriel Charpentier, Andrey Kutuzov\\nSummary: Training large language models requires vast amounts of data, posing a\\nchallenge for less widely spoken languages like Norwegian and even more so for\\ntruly low-resource languages like S\\\\'ami. To address this issue, we present a\\nnovel three-stage continual training approach. We also experiment with\\ncombining causal and masked language modeling to get more flexible models.\\nBased on our findings, we train, evaluate, and openly release a new large\\ngenerative language model for Norwegian Bokm\\\\r{a}l, Nynorsk, and Northern\\nS\\\\'ami with 11.4 billion parameters: NorMistral-11B.\\n\\nPublished: 2024-09-26\\nTitle: Enhancing elusive clues in knowledge learning by contrasting attention of language models\\nAuthors: Jian Gao, Xiao Zhang, Ji Wu, Miao Li\\nSummary: Causal language models acquire vast amount of knowledge from general text\\ncorpus during pretraining, but the efficiency of knowledge learning is known to\\nbe unsatisfactory, especially when learning from knowledge-dense and\\nsmall-sized corpora. The deficiency can come from long-distance dependencies\\nwhich are hard to capture by language models, and overfitting to co-occurrence\\npatterns and distracting clues in the training text. To address these issues,\\nthe paper proposes a method to enhance knowledge learning during language model\\npretraining, by enhancing elusive but important clues in text discovered by the\\nlanguage model themselves. We found that larger language models pay more\\nattention to non-obvious but important clues, which are often overlooked by\\nsmaller language models. Therefore, we can identify these clues by contrasting\\nthe attention weights of large and small language models. We use the identified\\nclues as a guide to perform token-dropout data augmentation on the training\\ntext, and observed a significant boost in both small and large models'\\nperformance in fact memorization. This shows that the behavior contrast between\\nmore and less-performant language models contains important clues for knowledge\\nlearning, and it can be ``amplified\\\" for a straight-forward improvement in\\nknowledge learning efficiency.\"\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://paperswithcode.com/paper/small-language-models-survey-measurements-and\", \"content\": \"Small Language Models: Survey, Measurements, and Insights | Papers With Code Subscribe to the PwC Newsletter Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. Add a new code entry for this paper Remove a code repository from this paper Add a task. Add a task Add a method Edit Datasets Add or remove datasets introduced in this paper: Add or remove other datasets used in this paper: Paper introduces a new dataset? Add a new dataset here Focusing on transformer-based, decoder-only language models with 100M-5B parameters, we survey 59 state-of-the-art open-source SLMs, analyzing their technical innovations across three axes: architectures, training datasets, and training algorithms. Benchmarking Decoder In-Context Learning Language Modelling Large Language Model Survey No methods listed for this paper.\"}, {\"url\": \"https://arxiv.org/abs/2409.15790\", \"content\": \"[2409.15790] Small Language Models: Survey, Measurements, and Insights > cs > arXiv:2409.15790 arXiv:2409.15790 (cs) Title:Small Language Models: Survey, Measurements, and Insights View a PDF of the paper titled Small Language Models: Survey, Measurements, and Insights, by Zhenyan Lu and 7 other authors Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) arXiv:2409.15790 [cs.CL] (or arXiv:2409.15790v1 [cs.CL] for this version) View a PDF of the paper titled Small Language Models: Survey, Measurements, and Insights, by Zhenyan Lu and 7 other authors cs cs.AI Bibliographic and Citation Tools Bibliographic Explorer Toggle Litmaps Toggle scite.ai Toggle Links to Code Toggle DagsHub Toggle GotitPub Toggle Links to Code Toggle ScienceCast Toggle Replicate Toggle Spaces Toggle Spaces Toggle Connected Papers Toggle Core recommender toggle\"}, {\"url\": \"https://arxiv.org/abs/2410.20011\", \"content\": \"> cs > arXiv:2410.20011 arXiv:2410.20011 (cs) View a PDF of the paper titled A Survey of Small Language Models, by Chien Van Nguyen and 27 other authors Subjects:Computation and Language (cs.CL)Cite as:arXiv:2410.20011 [cs.CL]\\u00a0(or arXiv:2410.20011v1 [cs.CL] for this version)\\u00a0https://doi.org/10.48550/arXiv.2410.20011Focus to learn morearXiv-issued DOI via DataCite View a PDF of the paper titled A Survey of Small Language Models, by Chien Van Nguyen and 27 other authors Bibliographic Explorer Toggle Connected Papers Toggle Litmaps Toggle scite.ai Toggle alphaXiv Toggle Links to Code Toggle DagsHub Toggle GotitPub Toggle Huggingface Toggle Links to Code Toggle ScienceCast Toggle Replicate Toggle Spaces Toggle Spaces Toggle Core recommender toggle Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy.\"}, {\"url\": \"https://www.aimodels.fyi/papers/arxiv/comprehensive-survey-small-language-models-era-large\", \"content\": \"Plain English Explanation. Language models are artificial intelligence systems that can understand and generate human-like text. Small language models (SLMs) are a type of language model that are relatively compact and efficient compared to the large language models (LLMs) that have become increasingly popular in recent years.. This paper explores the various aspects of SLMs, including the\"}, {\"url\": \"https://paperswithcode.com/paper/small-language-models-survey-measurements-and/review/\", \"content\": \"Paper Small Language Models: Survey, Measurements, and Insights Small language models (SLMs), despite their widespread adoption in modern smart devices, have received significantly less academic attention compared to their large language model (LLM) counterparts, which are predominantly deployed in data centers and cloud environments.\"}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----research node----\n",
      "----router----\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_nRyUDnJlbdhLsMgZpvpANBhG)\n",
      " Call ID: call_nRyUDnJlbdhLsMgZpvpANBhG\n",
      "  Args:\n",
      "    query: recent papers on Small Language Models\n",
      "  tavily_search_results_json (call_YsbNzgNsQNlsUpcwCGjbqY7x)\n",
      " Call ID: call_YsbNzgNsQNlsUpcwCGjbqY7x\n",
      "  Args:\n",
      "    query: recent papers on Small Language Models\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(resume={\"data\": None})\n",
    "\n",
    "events = app.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    try:\n",
    "        for msg in event[\"agent_outcome\"]:\n",
    "            msg.pretty_print()\n",
    "    except Exception as e:\n",
    "        HumanMessage(event[\"input\"]).pretty_print()\n",
    "    print(\"-----\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = app.stream(input=None, config=config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    try:\n",
    "        for msg in event[\"agent_outcome\"]:\n",
    "            msg.pretty_print()\n",
    "    except Exception as e:\n",
    "        HumanMessage(event[\"input\"]).pretty_print()\n",
    "    print(\"-----\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = app.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
