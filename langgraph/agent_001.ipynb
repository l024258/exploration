{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/L024258/lilly_work/github-copilot/exploration/langgraph/..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory and add the parent directory to the Python path\n",
    "current_working_directory = os.getcwd()\n",
    "print(os.path.join(current_working_directory, \"..\"))\n",
    "sys.path.append(os.path.join(current_working_directory, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Graph state\n",
    "\n",
    "State is the object that is passed between nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage, AnyMessage\n",
    "import operator\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    agent_outcome: List[AnyMessage]\n",
    "    chat_history: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.llm import LLM\n",
    "\n",
    "model = LLM('gpt-4o-mini')\n",
    "llm = model.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the agent (node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "def research_agent(data):\n",
    "    print(data)\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant\"\n",
    "                \"\\nUser Query: {input}\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = prompt | llm\n",
    "    result = agent.invoke(data)\n",
    "    return {\n",
    "                'agent_outcome': [result],\n",
    "                'chat_history': [\"User: \" + data['input'] + \"\\n AI Message: \" + result.content],\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"research\", research_agent)\n",
    "workflow.set_entry_point(\"research\")\n",
    "\n",
    "app = workflow.compile()\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"input\": \"What are the recent papers on Small Language Models?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`invoke()` method is used to run the workflow. It runs the entire graph (workflow) synchronously. \n",
    "\n",
    "It takes the input data and returns the final state of the workflow. \n",
    "\n",
    "The final state contains the output of the last agent that was executed in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What are the recent papers on Small Language Models?', 'chat_history': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the recent papers on Small Language Models?',\n",
       " 'agent_outcome': [AIMessage(content='As of my last update in October 2023, I can\\'t access real-time databases or the internet to provide the most recent papers. However, I can suggest some strategies for finding recent papers on small language models:\\n\\n1. **arXiv.org**: This is a repository for research papers in various fields, including computer science and artificial intelligence. You can search for \"small language models\" or related keywords to find the latest papers.\\n\\n2. **Google Scholar**: Use Google Scholar to search for recent publications. You can set the search filter to show only papers published in the last year or so.\\n\\n3. **Conference Proceedings**: Check the proceedings of major AI and NLP conferences such as ACL, EMNLP, NeurIPS, and ICML. They often feature cutting-edge research on language models.\\n\\n4. **Research Journals**: Look into journals like the Journal of Machine Learning Research (JMLR) or Transactions of the Association for Computational Linguistics (TACL) for peer-reviewed articles.\\n\\n5. **Social Media and Research Networks**: Platforms like ResearchGate, Twitter, and LinkedIn can be useful for following researchers and institutions that focus on language models.\\n\\nIf you have access to specific databases or libraries, you can also use them to search for the latest research articles.', response_metadata={'token_usage': {'completion_tokens': 262, 'prompt_tokens': 27, 'total_tokens': 289, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f3927aa00d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-c9adee7b-aa3c-4ecb-a17b-4f0445fc1baf-0', usage_metadata={'input_tokens': 27, 'output_tokens': 262, 'total_tokens': 289})],\n",
       " 'chat_history': ['User: What are the recent papers on Small Language Models?\\n AI Message: As of my last update in October 2023, I can\\'t access real-time databases or the internet to provide the most recent papers. However, I can suggest some strategies for finding recent papers on small language models:\\n\\n1. **arXiv.org**: This is a repository for research papers in various fields, including computer science and artificial intelligence. You can search for \"small language models\" or related keywords to find the latest papers.\\n\\n2. **Google Scholar**: Use Google Scholar to search for recent publications. You can set the search filter to show only papers published in the last year or so.\\n\\n3. **Conference Proceedings**: Check the proceedings of major AI and NLP conferences such as ACL, EMNLP, NeurIPS, and ICML. They often feature cutting-edge research on language models.\\n\\n4. **Research Journals**: Look into journals like the Journal of Machine Learning Research (JMLR) or Transactions of the Association for Computational Linguistics (TACL) for peer-reviewed articles.\\n\\n5. **Social Media and Research Networks**: Platforms like ResearchGate, Twitter, and LinkedIn can be useful for following researchers and institutions that focus on language models.\\n\\nIf you have access to specific databases or libraries, you can also use them to search for the latest research articles.']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(input=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in app.stream(input=inputs):\n",
    "    pprint.pp(s)\n",
    "    print(list(s.values())[0]['agent_outcome'][0].content)\n",
    "    print(\"-----\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_app_updates(user_input: str, chat_history: list):\n",
    "    inputs = {\n",
    "        \"input\": user_input,\n",
    "        \"chat_history\": chat_history\n",
    "    }\n",
    "    for event in app.stream(input=inputs):\n",
    "        for value in event.values():\n",
    "            response = value[\"agent_outcome\"][-1].content\n",
    "            conv = value[\"chat_history\"][-1]\n",
    "    return response, conv\n",
    "\n",
    "chat_history = []\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        response, conv = stream_app_updates(user_input, chat_history)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        print(\"User: \" + user_input)\n",
    "        response, conv = stream_app_updates(user_input, chat_history)\n",
    "        break\n",
    "    print(\"Assistant:\", response)\n",
    "    chat_history.append(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
