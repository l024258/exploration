{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory and add the parent directory to the Python path\n",
    "current_working_directory = os.getcwd()\n",
    "print(os.path.join(current_working_directory, \"..\"))\n",
    "sys.path.append(os.path.join(current_working_directory, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import AutoConfig\n",
    "config = AutoConfig(search_path='./../.env')\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = config('AZURE_OPENAI_API_KEY')\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = config('AZURE_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from typing import List, Tuple\n",
    "\n",
    "def load_doc_from_urls(urls:List[str],\n",
    "                       tags:List[str],\n",
    "                       tag_classes:List[str]):\n",
    "    urls = tuple(urls)\n",
    "    tag = tuple(tags)\n",
    "    tag_classes = tuple(tag_classes)\n",
    "\n",
    "    # Load, chunk and index the contents of the blog.\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=urls,\n",
    "        bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer(tag,\n",
    "                class_=tag_classes\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    docs = loader.load_and_split()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a detailed summary of the content.\")\n",
    "    highlights: str = Field(description=\"Provide the highlights of the content.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "trend_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"\"\"Analyse and Extract the key themes/topics from the provided accepted papers in the confernce. \n",
    "     Also provide the papers and keywords related to the topic.\n",
    "     Make sure all the papers are covered. If they do not fall into any theme or topic, add them to Others.\n",
    "     {input}\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "                openai_api_version=config('AZURE_CHAT_OPENAI_API_VERSION'),\n",
    "                azure_deployment=config('AZURE_GPT4o_mini_CHAT_OPENAI_DEPLOYMENT'),\n",
    "                temperature=0,\n",
    "                max_tokens=4096\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "\n",
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = llm.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()\n",
    "trend_chain = trend_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conference_trend_analysis():\n",
    "    docs = load_doc_from_urls(\n",
    "    urls=['https://2024.emnlp.org/program/accepted_main_conference/',\n",
    "          'https://2024.aclweb.org/program/main_conference_papers/',\n",
    "          'https://2024.naacl.org/program/accepted_papers/'],\n",
    "    tags=['strong',],\n",
    "    tag_classes=[] \n",
    ")\n",
    "\n",
    "    result = tagging_chain.invoke({\"input\": docs})\n",
    "    for key, value in result.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    result = trend_chain.invoke({\"input\": docs})\n",
    "    print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conference_trend_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_daily_trend_analysis():\n",
    "    docs = load_doc_from_urls(\n",
    "        urls=['https://arxiv.org/list/cs.AI/recent?skip=0&show=2000',\n",
    "            'https://arxiv.org/list/cs.CL/recent?skip=0&show=2000',\n",
    "            'https://arxiv.org/list/cs.CV/recent?skip=0&show=2000',\n",
    "            'https://arxiv.org/list/cs.IR/recent?skip=0&show=2000'],\n",
    "        tags=['div',],\n",
    "        tag_classes=['list-title mathjax'] \n",
    "    )\n",
    "\n",
    "    result = tagging_chain.invoke({\"input\": docs})\n",
    "    for key, value in result.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    result = trend_chain.invoke({\"input\": docs})\n",
    "    print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_daily_trend_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
