{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/L024258/lilly_work/github-copilot/exploration/applications/..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory and add the parent directory to the Python path\n",
    "current_working_directory = os.getcwd()\n",
    "print(os.path.join(current_working_directory, \"..\"))\n",
    "sys.path.append(os.path.join(current_working_directory, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import AutoConfig\n",
    "config = AutoConfig(search_path='./../.env')\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = config('AZURE_OPENAI_API_KEY')\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = config('AZURE_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "urls = ('https://2024.emnlp.org/program/accepted_main_conference/', \n",
    "        )\n",
    "tag = ('strong')\n",
    "tag_classes = ()\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=urls,\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(tag,\n",
    "            class_=tag_classes\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load_and_split()\n",
    "doc = docs[0]\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset GenerationMulti-News+: Cost-efficient Dataset Cleansing via LLM-based Data AnnotationFIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out DocumentPrompts have evil twinsTable Question Answering for Low-resourced Indic LanguagesImageInWords: Unlocking Hyper-Detailed Image DescriptionsLLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon GameplayWhen LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression DetectionSpeaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion ModelHateful Word in Context ClassificationEyes Don’t Lie: Subjective Hate Annotation and Detection with GazeNumeroLogic: Number Encoding for Enhanced LLMs’ Numerical ReasoningThinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language ModelsA Usage-centric Take on Intent Understanding in E-CommerceFine-Tuning or Retrieval? Comparing Knowledge Injection in LLMsSystematic Biases in LLM Simulations of DebatesStudying and Mitigating Biases in Sign Language Understanding ModelsUncertainty in Language Models: Assessment through Rank-CalibrationRoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool LearningLearning Planning-based Reasoning by Trajectories Collection and Process Reward SynthesizingScaling Properties of Speech Language Models“We Demand Justice!”: Towards Social Context Grounding of Political TextsAn Experimental Analysis on Evaluating Patent CitationsFine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?Consolidating Ranking and Relevance Predictions of Large Language Models through Post-ProcessingStrength Lies in Differences! Towards Effective Non-collaborative Dialogues via Tailored Strategy PlanningImpeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial PerturbationClustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality EstimationOn the Influence of Gender and Race in Romantic Relationship Prediction from Large Language ModelsEmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech ModelsOn Fake News Detection with LLM Enhanced Semantics MiningOn Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic ChoicesEvaluating the Instruction-Following Robustness of Large Language Models to Prompt InjectionA Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet ClassifiersMitigating the Alignment Tax of RLHFEvaluating Readability and Faithfulness of Concept-based ExplanationsPersonality-aware Student Simulation for Conversational Intelligent Tutoring SystemsMSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-MakingCoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted CrowdsTokenization Is More Than CompressionFLIRT: Feedback Loop In-context Red TeamingSuccessfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting CorrectionsParameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General TasksGeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image GenerationImproved Learned Sparse Retrieval with Entity VocabularyLet the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language ModelsLongEmbed: Extending Embedding Models for Long Context RetrievalMaking Large Language Models Better Reasoners with Orchestrated Streaming ExperiencesOvercome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in DialogueIntegrating Plutchik’s Theory with\n"
     ]
    }
   ],
   "source": [
    "print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a detailed summary of the content.\")\n",
    "    highlights: str = Field(description=\"Provide the highlights of the content.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "trend_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"\"\"Analyse and Extract the key themes/topics from the provided accepted papers in the confernce. \n",
    "     Also provide the papers and keywords related to the topic.\n",
    "     {input}\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "model = AzureChatOpenAI(\n",
    "                openai_api_version=config('AZURE_CHAT_OPENAI_API_VERSION'),\n",
    "                azure_deployment=config('AZURE_GPT4o_mini_CHAT_OPENAI_DEPLOYMENT'),\n",
    "                temperature=0,\n",
    "                max_tokens=4096\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/sfx4jy8s5bx23xxtplmtrj5c0000gp/T/ipykernel_50309/3622901728.py:5: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  convert_pydantic_to_openai_function(Overview)\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "\n",
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()\n",
    "trend_chain = trend_prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary\n",
      "The document contains a comprehensive list of accepted papers for the EMNLP 2024 conference, covering a wide range of topics related to large language models (LLMs), multimodal models, and various applications in natural language processing (NLP). Each entry includes the title of the paper, which reflects current research trends and challenges in the field, such as bias detection, reasoning capabilities, data augmentation, and model evaluation.\n",
      "highlights\n",
      "1. Papers focus on advancements in LLMs and their applications in various domains, including sentiment analysis, factuality detection, and multimodal understanding.\n",
      "2. Topics include bias mitigation, instruction tuning, and the integration of external knowledge into LLMs.\n",
      "3. Research addresses challenges like hallucinations in LLMs, the effectiveness of prompts, and the evaluation of model performance across different tasks.\n",
      "keywords\n",
      "Large Language Models, Multimodal Models, Natural Language Processing, Bias Detection, Instruction Tuning, Factuality, Data Augmentation, Model Evaluation.\n"
     ]
    }
   ],
   "source": [
    "result = tagging_chain.invoke({\"input\": docs})\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}\")\n",
    "    print(f\"{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are the key themes/topics extracted from the accepted papers at the conference, along with related papers and keywords:\\n\\n### 1. **Large Language Models (LLMs) and Their Applications**\\n   - **Papers:**\\n     - \"UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation\"\\n     - \"LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay\"\\n     - \"Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?\"\\n   - **Keywords:** LLMs, fine-tuning, zero-shot learning, sentiment classification, translation.\\n\\n### 2. **Bias and Fairness in AI**\\n   - **Papers:**\\n     - \"Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models\"\\n     - \"On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models\"\\n     - \"Mitigating the Alignment Tax of RLHF\"\\n   - **Keywords:** bias, fairness, debiasing, gender, race, alignment.\\n\\n### 3. **Multimodal Learning**\\n   - **Papers:**\\n     - \"ImageInWords: Unlocking Hyper-Detailed Image Descriptions\"\\n     - \"Towards Tool Use Alignment of Large Language Models\"\\n     - \"VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values\"\\n   - **Keywords:** multimodal, vision-language models, image descriptions, decision-making.\\n\\n### 4. **Data Quality and Annotation**\\n   - **Papers:**\\n     - \"Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation\"\\n     - \"Evaluating Readability and Faithfulness of Concept-based Explanations\"\\n     - \"A Survey on In-context Learning\"\\n   - **Keywords:** data quality, annotation, dataset cleansing, readability, explanations.\\n\\n### 5. **Reasoning and Understanding in AI**\\n   - **Papers:**\\n     - \"Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?\"\\n     - \"Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing\"\\n     - \"Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors\"\\n   - **Keywords:** reasoning, understanding, problem-solving, planning, visual reasoning.\\n\\n### 6. **Speech and Audio Processing**\\n   - **Papers:**\\n     - \"When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection\"\\n     - \"Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model\"\\n     - \"Towards Low-Resource Harmful Meme Detection with LMM Agents\"\\n   - **Keywords:** speech processing, audio, depression detection, low-resource.\\n\\n### 7. **Ethics and Safety in AI**\\n   - **Papers:**\\n     - \"Hateful Word in Context Classification\"\\n     - \"Evaluating Psychological Safety of Large Language Models\"\\n     - \"Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation\"\\n   - **Keywords:** ethics, safety, psychological safety, hate speech, self-supervised learning.\\n\\n### 8. **Knowledge Representation and Reasoning**\\n   - **Papers:**\\n     - \"Knowledge Graph Enhanced Large Language Model Editing\"\\n     - \"Exploring Reward Model Strength’s Impact on Language Models\"\\n     - \"Knowledge Verification to Nip Hallucination in the Bud\"\\n   - **Keywords:** knowledge representation, reasoning, knowledge graphs, verification, hallucination.\\n\\n### 9. **Evaluation and Benchmarking**\\n   - **Papers:**\\n     - \"A Comprehensive Empirical Assessment of Large Language Models\"\\n     - \"Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection\"\\n     - \"Benchmarking Vision Language Models for Cultural Understanding\"\\n   - **Keywords:** evaluation, benchmarking, instruction-following, cultural understanding.\\n\\n### 10. **Generative Models and Creativity**\\n   - **Papers:**\\n     - \"Generative Models for Automatic Medical Decision Rule Extraction from Text\"\\n     - \"Can Large Language Models Generate Culturally Relevant Commonsense QA Data?\"\\n     - \"Evaluating Diversity in Automatic Poetry Generation\"\\n   - **Keywords:** generative models, creativity, commonsense reasoning, poetry generation.\\n\\nThese themes reflect the current trends and research directions in the field of natural language processing and artificial intelligence as presented in the accepted papers at the conference.', response_metadata={'token_usage': {'completion_tokens': 932, 'prompt_tokens': 21776, 'total_tokens': 22708, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5154047bf2', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-95926ddf-6789-4217-9f27-9f5b4a0002ec-0', usage_metadata={'input_tokens': 21776, 'output_tokens': 932, 'total_tokens': 22708})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = trend_chain.invoke({\"input\": docs})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the key themes/topics extracted from the accepted papers at the conference, along with related papers and keywords:\n",
      "\n",
      "### 1. **Large Language Models (LLMs) and Their Applications**\n",
      "   - **Papers:**\n",
      "     - \"UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation\"\n",
      "     - \"LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay\"\n",
      "     - \"Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?\"\n",
      "   - **Keywords:** LLMs, fine-tuning, zero-shot learning, sentiment classification, translation.\n",
      "\n",
      "### 2. **Bias and Fairness in AI**\n",
      "   - **Papers:**\n",
      "     - \"Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models\"\n",
      "     - \"On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models\"\n",
      "     - \"Mitigating the Alignment Tax of RLHF\"\n",
      "   - **Keywords:** bias, fairness, debiasing, gender, race, alignment.\n",
      "\n",
      "### 3. **Multimodal Learning**\n",
      "   - **Papers:**\n",
      "     - \"ImageInWords: Unlocking Hyper-Detailed Image Descriptions\"\n",
      "     - \"Towards Tool Use Alignment of Large Language Models\"\n",
      "     - \"VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values\"\n",
      "   - **Keywords:** multimodal, vision-language models, image descriptions, decision-making.\n",
      "\n",
      "### 4. **Data Quality and Annotation**\n",
      "   - **Papers:**\n",
      "     - \"Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation\"\n",
      "     - \"Evaluating Readability and Faithfulness of Concept-based Explanations\"\n",
      "     - \"A Survey on In-context Learning\"\n",
      "   - **Keywords:** data quality, annotation, dataset cleansing, readability, explanations.\n",
      "\n",
      "### 5. **Reasoning and Understanding in AI**\n",
      "   - **Papers:**\n",
      "     - \"Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?\"\n",
      "     - \"Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing\"\n",
      "     - \"Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors\"\n",
      "   - **Keywords:** reasoning, understanding, problem-solving, planning, visual reasoning.\n",
      "\n",
      "### 6. **Speech and Audio Processing**\n",
      "   - **Papers:**\n",
      "     - \"When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection\"\n",
      "     - \"Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model\"\n",
      "     - \"Towards Low-Resource Harmful Meme Detection with LMM Agents\"\n",
      "   - **Keywords:** speech processing, audio, depression detection, low-resource.\n",
      "\n",
      "### 7. **Ethics and Safety in AI**\n",
      "   - **Papers:**\n",
      "     - \"Hateful Word in Context Classification\"\n",
      "     - \"Evaluating Psychological Safety of Large Language Models\"\n",
      "     - \"Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation\"\n",
      "   - **Keywords:** ethics, safety, psychological safety, hate speech, self-supervised learning.\n",
      "\n",
      "### 8. **Knowledge Representation and Reasoning**\n",
      "   - **Papers:**\n",
      "     - \"Knowledge Graph Enhanced Large Language Model Editing\"\n",
      "     - \"Exploring Reward Model Strength’s Impact on Language Models\"\n",
      "     - \"Knowledge Verification to Nip Hallucination in the Bud\"\n",
      "   - **Keywords:** knowledge representation, reasoning, knowledge graphs, verification, hallucination.\n",
      "\n",
      "### 9. **Evaluation and Benchmarking**\n",
      "   - **Papers:**\n",
      "     - \"A Comprehensive Empirical Assessment of Large Language Models\"\n",
      "     - \"Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection\"\n",
      "     - \"Benchmarking Vision Language Models for Cultural Understanding\"\n",
      "   - **Keywords:** evaluation, benchmarking, instruction-following, cultural understanding.\n",
      "\n",
      "### 10. **Generative Models and Creativity**\n",
      "   - **Papers:**\n",
      "     - \"Generative Models for Automatic Medical Decision Rule Extraction from Text\"\n",
      "     - \"Can Large Language Models Generate Culturally Relevant Commonsense QA Data?\"\n",
      "     - \"Evaluating Diversity in Automatic Poetry Generation\"\n",
      "   - **Keywords:** generative models, creativity, commonsense reasoning, poetry generation.\n",
      "\n",
      "These themes reflect the current trends and research directions in the field of natural language processing and artificial intelligence as presented in the accepted papers at the conference.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
