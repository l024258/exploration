{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/L024258/lilly_work/github-copilot/exploration/notebooks/..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory and add the parent directory to the Python path\n",
    "current_working_directory = os.getcwd()\n",
    "print(os.path.join(current_working_directory, \"..\"))\n",
    "sys.path.append(os.path.join(current_working_directory, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import AutoConfig\n",
    "config = AutoConfig(search_path='./../.env')\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = config('AZURE_OPENAI_API_KEY')\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = config('AZURE_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "urls = ('https://2024.emnlp.org/program/accepted_main_conference/', \n",
    "        )\n",
    "tag = ('strong')\n",
    "tag_classes = ()\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=urls,\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(tag,\n",
    "            class_=tag_classes\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load_and_split()\n",
    "doc = docs[0]\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset GenerationMulti-News+: Cost-efficient Dataset Cleansing via LLM-based Data AnnotationFIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out DocumentPrompts have evil twinsTable Question Answering for Low-resourced Indic LanguagesImageInWords: Unlocking Hyper-Detailed Image DescriptionsLLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon GameplayWhen LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression DetectionSpeaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion ModelHateful Word in Context ClassificationEyes Don’t Lie: Subjective Hate Annotation and Detection with GazeNumeroLogic: Number Encoding for Enhanced LLMs’ Numerical ReasoningThinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language ModelsA Usage-centric Take on Intent Understanding in E-CommerceFine-Tuning or Retrieval? Comparing Knowledge Injection in LLMsSystematic Biases in LLM Simulations of DebatesStudying and Mitigating Biases in Sign Language Understanding ModelsUncertainty in Language Models: Assessment through Rank-CalibrationRoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool LearningLearning Planning-based Reasoning by Trajectories Collection and Process Reward SynthesizingScaling Properties of Speech Language Models“We Demand Justice!”: Towards Social Context Grounding of Political TextsAn Experimental Analysis on Evaluating Patent CitationsFine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?Consolidating Ranking and Relevance Predictions of Large Language Models through Post-ProcessingStrength Lies in Differences! Towards Effective Non-collaborative Dialogues via Tailored Strategy PlanningImpeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial PerturbationClustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality EstimationOn the Influence of Gender and Race in Romantic Relationship Prediction from Large Language ModelsEmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech ModelsOn Fake News Detection with LLM Enhanced Semantics MiningOn Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic ChoicesEvaluating the Instruction-Following Robustness of Large Language Models to Prompt InjectionA Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet ClassifiersMitigating the Alignment Tax of RLHFEvaluating Readability and Faithfulness of Concept-based ExplanationsPersonality-aware Student Simulation for Conversational Intelligent Tutoring SystemsMSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-MakingCoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted CrowdsTokenization Is More Than CompressionFLIRT: Feedback Loop In-context Red TeamingSuccessfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting CorrectionsParameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General TasksGeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image GenerationImproved Learned Sparse Retrieval with Entity VocabularyLet the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language ModelsLongEmbed: Extending Embedding Models for Long Context RetrievalMaking Large Language Models Better Reasoners with Orchestrated Streaming ExperiencesOvercome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in DialogueIntegrating Plutchik’s Theory with\n"
     ]
    }
   ],
   "source": [
    "print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a detailed summary of the content.\")\n",
    "    highlights: str = Field(description=\"Provide the highlights of the content.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "trend_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"\"\"Analyse and Extract the key themes/topics from the provided accepted papers in the confernce. \n",
    "     Also provide the papers and keywords related to the topic.\n",
    "     {input}\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "model = AzureChatOpenAI(\n",
    "                openai_api_version=config('AZURE_CHAT_OPENAI_API_VERSION'),\n",
    "                azure_deployment=config('AZURE_GPT4_CHAT_OPENAI_DEPLOYMENT'),\n",
    "                temperature=0,\n",
    "                max_tokens=1024\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "\n",
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()\n",
    "trend_chain = trend_prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary\n",
      "The document lists the titles of various research papers and projects that were accepted for the main conference of EMNLP 2024. The topics cover a wide range of areas in natural language processing, including but not limited to, domain generalization, dataset cleansing, factual inconsistency detection, sentiment classification, language model fine-tuning, bias mitigation, language model evaluation, and many more.\n",
      "highlights\n",
      "The document provides a comprehensive list of research papers and projects accepted for the main conference of EMNLP 2024. The topics are diverse, covering various aspects of natural language processing.\n",
      "keywords\n",
      "EMNLP 2024, research papers, projects, natural language processing, domain generalization, dataset cleansing, factual inconsistency detection, sentiment classification, language model fine-tuning, bias mitigation, language model evaluation\n"
     ]
    }
   ],
   "source": [
    "result = tagging_chain.invoke({\"input\": docs})\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}\")\n",
    "    print(f\"{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The key themes/topics from the accepted papers in the conference include:\\n\\n1. Large Language Models (LLMs): Various aspects of LLMs are discussed, including their capabilities, limitations, biases, and potential improvements. \\n\\n2. Multilingual and Cross-Lingual Models: Several papers focus on the challenges and advancements in multilingual and cross-lingual natural language processing.\\n\\n3. Machine Learning and Deep Learning: Many papers explore different aspects of machine learning and deep learning, including model fine-tuning, optimization, and evaluation.\\n\\n4. Knowledge Graphs: Some papers discuss the use of knowledge graphs for tasks like information extraction and question answering.\\n\\n5. Dialogue Systems and Conversational AI: Several papers focus on the development and evaluation of dialogue systems and conversational AI.\\n\\n6. Sentiment Analysis and Emotion Detection: Some papers explore sentiment analysis and emotion detection in various languages and contexts.\\n\\n7. Bias and Fairness in AI: A number of papers discuss the detection and mitigation of bias in AI models, particularly in the context of language models.\\n\\n8. Information Retrieval: Some papers focus on improving information retrieval using large language models.\\n\\n9. Visual and Multimodal Models: Several papers discuss models that integrate visual and textual information.\\n\\n10. Medical and Healthcare Applications: Some papers explore the application of NLP and AI in the medical and healthcare domain.\\n\\n11. Data Annotation and Dataset Generation: A number of papers discuss methods for data annotation and dataset generation, particularly in the context of LLMs.\\n\\n12. Text Generation: Several papers focus on text generation tasks, including summarization, translation, and creative writing.\\n\\n13. Speech Recognition and Synthesis: Some papers explore advancements in speech recognition and synthesis.\\n\\n14. Evaluation Metrics and Benchmarks: Many papers propose new evaluation metrics and benchmarks for various NLP tasks.\\n\\n15. Privacy and Security in AI: A few papers discuss issues related to privacy and security in AI, including data privacy and model watermarking.\\n\\n16. Code Generation and Programming Language Processing: Some papers focus on code generation and the processing of programming languages using LLMs.\\n\\n17. Question Answering: Several papers discuss advancements in question answering systems, particularly in the context of LLMs.\\n\\n18. Social Media Analysis: Some papers explore the analysis of social media data, including the detection of hate speech and misinformation.\\n\\n19. Legal and Political Text Analysis: A few papers discuss the analysis of legal and political texts using LLMs.\\n\\n20. Sign Language Understanding: Some papers focus on the understanding and processing of sign language.\\n\\n21. Uncertainty Estimation: A few papers discuss methods for uncertainty estimation in language models.\\n\\n22. Multimodal Learning: Several papers discuss models that integrate multiple modalities, such as text, speech, and images.\\n\\n23. Reinforcement Learning: Some papers explore the application of reinforcement learning in NLP tasks.\\n\\n24. Neural Networks and Transformers: Many papers discuss various aspects of neural networks and transformers, including their structure, optimization, and evaluation.\\n\\n25. Semantic Parsing and Reasoning: Several papers focus on semantic parsing and reasoning tasks.\\n\\n26. Text Classification: Some papers discuss advancements in text classification tasks.\\n\\n27. Named Entity Recognition: A few papers focus on named entity recognition tasks.\\n\\n28. Text-to-Image Generation: Some papers discuss text-to-image generation tasks.\\n\\n29. Text Summarization: Several papers focus on text summarization tasks.\\n\\n30. Text-to-Speech and Speech-to-Text Models: Some papers explore advancements in text-to-speech and speech-to-text models.\\n\\n31. Text Mining and Information Extraction: A few papers discuss text mining and information extraction tasks.\\n\\n32. Text Embeddings: Some papers focus on text embeddings and their applications.\\n\\n33. Text Clustering: A few papers discuss text clustering tasks.\\n\\n34. Text Sentiment Analysis: Some papers focus on text sentiment analysis tasks.\\n\\n35. Text Watermarking: A few papers discuss text watermarking techniques.\\n\\n36. Text Simplification: Some papers focus on text simplification tasks.\\n\\n37. Text Correction: A few papers discuss text correction tasks, including spelling and grammatical error correction.\\n\\n38. Text Segmentation: Some papers focus on text segmentation tasks.\\n\\n39. Text Translation: Several papers discuss text translation tasks, including machine translation and cross-lingual transfer.\\n\\n40. Text Understanding: Many papers discuss various aspects of text understanding, including semantic understanding, syntactic understanding, and pragmatic understanding.\\n\\n41. Text Retrieval: Some papers focus on text retrieval tasks.\\n\\n42. Text Annotation: A few papers discuss text annotation tasks.\\n\\n43. Text Generation: Several papers focus on text generation tasks, including creative writing, code generation, and dialogue generation.\\n\\n44. Text Evaluation: Many papers propose new methods for evaluating various aspects of text, including its quality, coherence, and factuality.\\n\\n45. Text Analysis: Some papers focus on text analysis tasks, including sentiment analysis, topic modeling, and text classification.\\n\\n46. Text Processing: A few papers discuss various aspects of text processing, including tokenization, parsing, and text normalization.\\n\\n47. Text Representation: Some papers', response_metadata={'token_usage': {'completion_tokens': 1024, 'prompt_tokens': 22299, 'total_tokens': 23323, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4-32k', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None, 'content_filter_results': {}}, id='run-c0cab3fa-2720-47ec-810e-0a9f542dbd5b-0', usage_metadata={'input_tokens': 22299, 'output_tokens': 1024, 'total_tokens': 23323})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = trend_chain.invoke({\"input\": docs})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key themes/topics from the accepted papers in the conference include:\n",
      "\n",
      "1. Large Language Models (LLMs): Various aspects of LLMs are discussed, including their capabilities, limitations, biases, and potential improvements. \n",
      "\n",
      "2. Multilingual and Cross-Lingual Models: Several papers focus on the challenges and advancements in multilingual and cross-lingual natural language processing.\n",
      "\n",
      "3. Machine Learning and Deep Learning: Many papers explore different aspects of machine learning and deep learning, including model fine-tuning, optimization, and evaluation.\n",
      "\n",
      "4. Knowledge Graphs: Some papers discuss the use of knowledge graphs for tasks like information extraction and question answering.\n",
      "\n",
      "5. Dialogue Systems and Conversational AI: Several papers focus on the development and evaluation of dialogue systems and conversational AI.\n",
      "\n",
      "6. Sentiment Analysis and Emotion Detection: Some papers explore sentiment analysis and emotion detection in various languages and contexts.\n",
      "\n",
      "7. Bias and Fairness in AI: A number of papers discuss the detection and mitigation of bias in AI models, particularly in the context of language models.\n",
      "\n",
      "8. Information Retrieval: Some papers focus on improving information retrieval using large language models.\n",
      "\n",
      "9. Visual and Multimodal Models: Several papers discuss models that integrate visual and textual information.\n",
      "\n",
      "10. Medical and Healthcare Applications: Some papers explore the application of NLP and AI in the medical and healthcare domain.\n",
      "\n",
      "11. Data Annotation and Dataset Generation: A number of papers discuss methods for data annotation and dataset generation, particularly in the context of LLMs.\n",
      "\n",
      "12. Text Generation: Several papers focus on text generation tasks, including summarization, translation, and creative writing.\n",
      "\n",
      "13. Speech Recognition and Synthesis: Some papers explore advancements in speech recognition and synthesis.\n",
      "\n",
      "14. Evaluation Metrics and Benchmarks: Many papers propose new evaluation metrics and benchmarks for various NLP tasks.\n",
      "\n",
      "15. Privacy and Security in AI: A few papers discuss issues related to privacy and security in AI, including data privacy and model watermarking.\n",
      "\n",
      "16. Code Generation and Programming Language Processing: Some papers focus on code generation and the processing of programming languages using LLMs.\n",
      "\n",
      "17. Question Answering: Several papers discuss advancements in question answering systems, particularly in the context of LLMs.\n",
      "\n",
      "18. Social Media Analysis: Some papers explore the analysis of social media data, including the detection of hate speech and misinformation.\n",
      "\n",
      "19. Legal and Political Text Analysis: A few papers discuss the analysis of legal and political texts using LLMs.\n",
      "\n",
      "20. Sign Language Understanding: Some papers focus on the understanding and processing of sign language.\n",
      "\n",
      "21. Uncertainty Estimation: A few papers discuss methods for uncertainty estimation in language models.\n",
      "\n",
      "22. Multimodal Learning: Several papers discuss models that integrate multiple modalities, such as text, speech, and images.\n",
      "\n",
      "23. Reinforcement Learning: Some papers explore the application of reinforcement learning in NLP tasks.\n",
      "\n",
      "24. Neural Networks and Transformers: Many papers discuss various aspects of neural networks and transformers, including their structure, optimization, and evaluation.\n",
      "\n",
      "25. Semantic Parsing and Reasoning: Several papers focus on semantic parsing and reasoning tasks.\n",
      "\n",
      "26. Text Classification: Some papers discuss advancements in text classification tasks.\n",
      "\n",
      "27. Named Entity Recognition: A few papers focus on named entity recognition tasks.\n",
      "\n",
      "28. Text-to-Image Generation: Some papers discuss text-to-image generation tasks.\n",
      "\n",
      "29. Text Summarization: Several papers focus on text summarization tasks.\n",
      "\n",
      "30. Text-to-Speech and Speech-to-Text Models: Some papers explore advancements in text-to-speech and speech-to-text models.\n",
      "\n",
      "31. Text Mining and Information Extraction: A few papers discuss text mining and information extraction tasks.\n",
      "\n",
      "32. Text Embeddings: Some papers focus on text embeddings and their applications.\n",
      "\n",
      "33. Text Clustering: A few papers discuss text clustering tasks.\n",
      "\n",
      "34. Text Sentiment Analysis: Some papers focus on text sentiment analysis tasks.\n",
      "\n",
      "35. Text Watermarking: A few papers discuss text watermarking techniques.\n",
      "\n",
      "36. Text Simplification: Some papers focus on text simplification tasks.\n",
      "\n",
      "37. Text Correction: A few papers discuss text correction tasks, including spelling and grammatical error correction.\n",
      "\n",
      "38. Text Segmentation: Some papers focus on text segmentation tasks.\n",
      "\n",
      "39. Text Translation: Several papers discuss text translation tasks, including machine translation and cross-lingual transfer.\n",
      "\n",
      "40. Text Understanding: Many papers discuss various aspects of text understanding, including semantic understanding, syntactic understanding, and pragmatic understanding.\n",
      "\n",
      "41. Text Retrieval: Some papers focus on text retrieval tasks.\n",
      "\n",
      "42. Text Annotation: A few papers discuss text annotation tasks.\n",
      "\n",
      "43. Text Generation: Several papers focus on text generation tasks, including creative writing, code generation, and dialogue generation.\n",
      "\n",
      "44. Text Evaluation: Many papers propose new methods for evaluating various aspects of text, including its quality, coherence, and factuality.\n",
      "\n",
      "45. Text Analysis: Some papers focus on text analysis tasks, including sentiment analysis, topic modeling, and text classification.\n",
      "\n",
      "46. Text Processing: A few papers discuss various aspects of text processing, including tokenization, parsing, and text normalization.\n",
      "\n",
      "47. Text Representation: Some papers\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
